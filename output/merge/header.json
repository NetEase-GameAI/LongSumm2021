{"1000": "unsupervised learning approaches appear to be a natural solution to this problem, as they require only unannotated text for train. unfortunately, the best completely unsupervised english pos tagger, making its practical usability questionable best. our method does not assume any knowledge about the target language across eight european languages, our approach results in an average absolute improvement of over a state-of-the-art baseline, and over vanilla hidden markov models induced with the expectation maximization algorithm.", "1001": "this paper introduces a novel fv representation for sequences that is derived from rnns. the proposed representation is sensitive to the element ordering in the sequence and provides a richer model than the additive bag model typically used for conventional fvs. state of the art results are obtained in two central but distant tasks, which both rely on sequences: video action recognition and image annotation. although the image annotation and video action recognition tasks are quite different, a surprising boost in performance in the video action recognition task was achieved by using a transfer learning approach from the image annotation task. specifically, the vgg image embedding of a frame is projected using a linear transformation which was learned on matching images and sentences by the canonical correlation analysis (cca) algorithm the proposed rnn-fv method achieves state-of-theart results in action recognition on the hmdb51 and ucf101 datasets. a transfer learning result from the image annotation task to the video action recognition task was shown. the con- ceptual distance between these two tasks makes this result both interesting and surprising.", "1002": "currently, no largescale training data is available for the task of scientific paper summarization. in this paper, we propose a novel method that automatically generates summaries for scientific papers by utilizing videos of talks at scientific conferences. we hypothesize that such talks constitute a coherent description of papers, and their content and can form the basis for good summaries.", "1003": "emotion detection from text has become a popular task due to the key role of emotions in human-machine interaction. while the aforementioned approach utilizes bow representation and linear classi ers, neural network methods are based on dense vector representations of text samples (word embedding) and are nonlinear. such word embedding representation captures syntactic and semantic knowledge, which can improve the emotion detection task. generating high quality word vectors requires large-scale data and computing power. when generation is not an option, one can utilize pre-trained representations; the most popular pre-trained representations are based on word2vec and glove algorithms, and were trained on large corpora. to our knowledge, this is the rst research that shows how to utilize pre-trained representations for emotion detection.", "1004": "in this paper, we show that it is possible to automatically detect emotions being expressed and, second that it is possible to predict the emotional technique that is likely to be used by a human agent in a given situation. this analysis reflects our ultimate goal: to enable a computer system to discern the emotions expressed by human customers, and to develop computerized tools that mimic the emotional technique used by a human customer service agent in a given situation. we show first that it is possible to automatically detect emotions being expressed and, second that it is possible to predict the emotional technique that is likely to be used by a human agent in a given situation.", "1005": "few-shot learning (fsl) is a technique that learns to adapt to novel tasks that it will encounter during test time. the goal of meta-learning is to find a base model that is easily adapted to the specific task at hand, so that it will generalize well to tasks built from novel unseen categories and fulfill the goal of fsc. to this end, we employ tools inspired by the differentiable neural architecture search (d-nas) literature in order to optimize the architecture for fsl without over-fitting. additionally, to make the architecture task adaptive, we propose the concept of metadapt controller modules. these modules are added to the model and are meta-trained to predict the optimal network connections for a given novel task. to avoid over-fitting, a bi-level (two-fold) optimization is performed where first the operation layers weights are trained on one fold of the data and then the connections weights are trained on the other fold.", "1006": "virtual agents are becoming a prominent channel of interaction in customer service. not all customer interactions are smooth, however, and some can become almost comically bad. in such instances, a human agent might need to step in and salvage the conversation. detecting bad conversations is important since disappointing customer service may threaten customer loyalty and impact revenue. in this paper, we outline an approach to detecting such egregious conversations, using behavioral cues from the user, patterns in agent responses, and useragent interaction. using logs of two commercial systems, we show that using these features improves the detection f1-score by around over using textual features alone. in addition, we show that those features are common across two quite different domains and, arguably, universal.", "1007": "convolutional neural networks (cnns) can be interpreted by projecting filters into image space, but for discrete sequence inputs cnns remain a mystery. we aim to understand the method by which the networks process and classify text. we examine common hypotheses to this problem: that filters, accompanied by global max-pooling, serve as ngram detectors. we show that filters do not maximize activations at the word-level, but instead form slot activation patterns that give different types of ngrams similar activation strengths. this provides empirical evidence that filters are not homogeneous. by clustering high-scoring ngrams according to their slot activation patterns we can identify the groups of linguistic patterns captured by a filter. we also show that filters sometimes opt to assign negative values to certain word activations in order to cause the ngrams which contain them to receive a low score despite having otherwise highly activating words. finally, we use these findings to suggest improvements to model-based and predictionbased interpretability of cnns for text.", "1008": "a summary generated by editnet may include sentences that were either extracted, or of both types. moreover, per considered sentence, editnet may decide not to take either of these decisions and completely reject the sentence. moreover, editnet implements a novel sentence rejection decision, allowing to correct initial sentence selection decisions which are predicted to negatively effect summarization quality. using the cnn/dailymail dataset we demonstrate that, editnets quality is highly competitive to that obtained by both state-of-the-art abstractive-only and extractive-only baselines.", "1009": "this paper presents dimsim, a learned ndimensional phonetic encoding for chinese along with a phonetic similarity algorithm, which uses the encoding to generate and rank phonetically similar chinese words. dimsim generates phonetically similar candidate words based on learned encodings that capture the pronunciation characteristics of pinyin initial, final, and tone components. the learning model derives accurate encodings by jointly considering pinyin phonetic characteristics, such as place of articulation and pronunciation methods, as well as high quality annotated training data sets. we compare dimsim to double metaphone(dm), minimum edit distance(med) and aline demonstrating that dimsim outperforms these algorithms by 7.5x on mean reciprocal rank, 1.4x on precision and 1.5x on recall on a real world dataset.", "1010": "relation detection is a key step in kbqa and is significantly different from general relation extraction tasks. we propose a novel kb relation detection model, hr-bilstm, that performs hierarchical matching between questions and kb relations. our model outperforms the previous methods on kb relation detection tasks and allows our kbqa system to achieve state-of-the-arts.", "1011": "in this paper, we propose a human-in-the-loop (huml) dictionary expansion approach that employs a lightweight neural language model coupled with tight huml supervision to assist the user in building and maintaining a domain-specific dictionary from an input text corpus. the approach is based on the explore/exploit paradigm to effectively discover new instances (explore) from the text corpus as well as predict new unseen terms not currently in the corpus using the accepted dictionary entries (exploit) . given an input text corpus and a set of seed examples, the proposed approach runs in two phases, explore and exploit, to identify new potential dictionary entries. the explore phase tries to identify similar instances to the dictionary entries that are present in the input corpus, using term vectors from the neural language model to calculate a similarity score. the exploit phase tries to construct more complex multiterm phrases by analyzing the single terms of the instances in the input dictionary.", "1012": "existing algorithms generally formulate the task as selection from a set of bounding box proposals obtained from deep net based systems. in this work, we demonstrate that we can cast the problem of textual grounding into a unified framework that permits efficient search over all possible bounding boxes.", "1013": "the use of perceptual features (pfs) in the context of learning implicit generative models through moment matching (mm) is not well studied. more specifically, we propose a new effective mm approach that learns implicit generative models by performing mean and covariance matching of features extracted from all convolutional layers of pretrained deep convnets. our proposed approach improves upon existing mm methods by: breaking away from adversarial learning; avoiding online learning of kernel functions; avoiding online learning of kernel functions; and being efficient with respect to both number of used moments and required minibatch size. our experimental results demonstrate that, due to the expressiveness of pfs from pretrained deep convnets, our method achieves stateoftheart results for challenging benchmarks.", "1014": "recommender systems aim to present items with high utility to the consumers utility may be into form utility: the item is desired as it is manifested, and time utility: the item is desired at the given point in time 28. in particular for durable goods, time utility is a function of inter-purchase duration within product category because consumers are unlikely to purchase two items in the same category in close temporal succession. moreover, purchase data, in contrast to rating data, is implicit with non-purchases not necessarily indicating dislike.", "1015": "personality is a set of traits which represent durable characteristics of a person. many models of personality exist while the most common one is the big five model, including: openness, conscientiousness, extraversion, agreeableness, and neuroticism. these traits were correlated with linguistic choices including lexicon and syntax (mairesse and walker, 2007). in this paper we study how to encode personality traits as part of neural response generation for conversational agents. our approach builds upon a sequence-to-sequence by adding an additional layer that represents the target set of personality traits, and a hidden layer that learns high-level personality based features. the response is then generated conditioned on these features.", "1016": "we introduce a stereo correspondence system implemented fully on event-based digital hardware, using a fully graph-based non von-neumann computation model, where no frames, arrays, or any other such data-structures are used. this is the first time that an end-to-end stereo pipeline from image acquisition and rectification, multi-scale spatiotemporal stereo correspondence, winner-take-all, to disparity regularization is implemented fully on event-based hardware. using a cluster of truenorth neurosynaptic processors, we demonstrate their ability to process bilateral event- based inputs streamed live by dynamic vision sensors (dvs), at up to 2,000 disparity maps per second, producing high fidelity disparities which are in turn used to reconstruct, at low power, the depth of events produced from rapidly changing scenes. experiments on real- world sequences demonstrate the ability of the system to take full advantage of the asynchronous and sparse nature of dvs sensors for low power depth reconstruction, in environments where conventional frame-based cameras connected to synchronous processors would be inefficient for rapidly moving objects.", "1017": "the task of learning the causal structure underlying a certain phenomenon is undertaken by connecting the set of conditional independences (cis) readable from the observational data, on the one side, with the set of corresponding constraints implied over the graphical structure, on the other, which are tied through a graphical criterion known as d-separation. in this paper, we investigate the more general setting where multiple observational and experimental distributions are available. we start with the simple observation that the invariances given by cis/dseparation are just one special type of constraints, which follow from the careful comparison of the different distributions available. remarkably, these new constraints are intrinsically connected with do-calculus in the context of soft-interventions. we then introduce a novel notion of interventional equivalence class of causal graphs with latent variables based on these invariances, which associates each graphical structure with a set of interventional distributions that respect the do-calculus rules. given a collection of distributions, two causal graphs are called interventionally equivalent if they are associated with the same family of interventional distributions, where the elements of the family are indistinguishable using the invariances obtained from a direct application of the calculus rules.", "1018": "neural program induction (npi) is a pragmatic approach toward modularizing reasoning process by translating a complex natural language query into a multistep executable program. while npi has been commonly trained with the gold program or its sketch, for realistic kbqa applications such programs are expensive to obtain there, practically only natural language answers can be provided for training. the resulting combinatorial explosion in program space, along with extremely sparse rewards, makes npi for kbqa ambitious and challenging. we present complex imperative program induction from terminal rewards (cipitr), an advanced neural programmer that mitigates reward sparsity with auxiliary rewards, and restricts the program space to semantically correct programs using high-level constraints, kb schema, and inferred answer type. for moderately complex queries requiring 2to 5-step programs, cipitr scores at least higher f1 than the competing systems. on one of the hardest class of programs (comparative reasoning) with steps, cipitr outperforms nsm by a factor of and kvmnet by a factor of further diverse program classes.", "1019": "the vast amounts of textual data end users need to consume motivates the need for automatic summarization an automatic summarizer gets as an input one or more documents and possibly also a limit on summary length (e.g., maximum number of words). the summarizer then needs to produce a textual summary that captures the most salient (general and informative) content parts within input documents. moreover, the summarizer may also be required to satisfy a specific user information need, expressed by one or more queries. therefore, the summarizer will need to produce a focused summary which includes the most relevant information to that need. while both saliency and focus goals should be considered within a query-focused summarization setting, these goals may be actually conflicting with each other higher saliency usually comes at the expense of lower focus and viceversa.", "1020": "in this paper we present a system that can synthesize speech with close to natural quality while running times faster than real-time on a standard cpu. the system is composed of three separate neural network blocks: prosody prediction, acoustic feature prediction and linear prediction coding net as a neural vocoder. this system can synthesize speech with close to natural quality while running times faster than real-time on a standard cpu. the modular setup of the system allows for simple adaptation to new voices with a small amount of data.", "1021": "in this paper we introduce the sobolev independence criterion (sic) , an interpretable dependency measure between a high dimensional random variable x and a response variable y sic decomposes to the sum of feature importance scores and hence can be used for nonlinear feature selection. sic can be seen as a gradient regularized integral probability metric (ipm) between the joint distribution of the two random variables and the product of their marginals. we use sparsity inducing gradient penalties to promote input sparsity of the critic of the ipm."}