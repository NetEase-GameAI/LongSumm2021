{"1000": "unsupervised learning approaches appear to be a natural solution to this problem, as they require only unannotated text for train. unfortunately, the best completely unsupervised english pos tagger, making its practical usability questionable at best. to bridge this gap, we consider a practically motivated scenario, in which we want to leverage existing resources from a resource-rich language study related but different multilingual grammar and tagger induction tasks, where it is assumed that no labeled data at all is available. algorithm bilingual pos induction require : parallel english and foreign language data de and df, unlabeled foreign training data f; english tagger. ensure: f, a set of parameters learned using a constrained unsupervised model. this paper proposes a graph - based framework for unsupervised pos tagging. in this framework, the vertices of the graph are labeled and unlabeled examples, and the edge weights encode the degree to which the examples they link have the same label graph construction for structured prediction problems such as pos tagging is nontrivial: on the one hand, using individual words as the vertices throws away the context. the word alignment methods do not use pos information. necessary for disambiguation; on the other hand, it is unclear how to define proposed a technique that uses graph based similarity between labeled and unlabeled parts of structured data in a discriminative framework for semi-supervised learning. to define a similarity function between the english and the foreign vertices, we rely on high-confidence word alignments. since our graph is built from a parallel corpus, we can use standard word alignment techniques to align the english sentences de 5note that many combinations are impossible giving a pmi value of 0; e.g., when the trigram type and the feature instantiation don t have words in common. and their foreign language translations df label propagation in the graph will provide coverage and high recall, and we therefore extract only intersected high-confidence alignments in this paper , we propose a supervised tagger that propagates the label distribution from the english vertices to the connected foreign language vertices (v lf) at the periphery of the graph. in the first stage, we run a single step of label propagation, which transfers the label distributions from the english vertices to the connected foreign language vertices (v lf) at the periphery of the graph. note that many foreign vertices will not be connected to any english vertices. we use a squared loss to neighboring vertices that have different label distributions: qi qj2 y ( qi ( y) qj ( y) 2, and additionally regularize the label distributions towards the uniform distribution u over all possible labels y it can be shown that this objective is convex in q. the first term regularizer term is the graph smoothness which encourages the distributions of similar vertices ( large wij) to be similar. the second term regularizer term is a regularizer and encourages all type marginals to be uniform. if an unlabeled vertex does not have a path to any labeled vertex, this term ensures that the converged marginal for this vertex will be uniform over all tags, allowing the middle word of such an unlabeled vertex to take on any of the possible tags. this paper proposes a new approach to pos induction in languages for which no labeled resources are available. in this paper, we propose a graph - based model for language classification that is able to extract the constraint feature for all foreign word types. the graph is constructed using million trigrams; we chose these by truncating the parallel datasets up to the number of sentence pairs that contained million trigrams. we used c as the l2 regularization constant in (eq. 10) and trained both em and l-bfgs for iterations. when extracting the vector tx used to compute the constraint feature from the graph, it performs better than the hitherto state-of-theart feature-hmm baseline, and better than the no lp setting overall, when we macro-average the accuracy over all languages. our full model outperforms the no lp setting because it has better vocabulary coverage and allows the extraction of the constraint feature. for comparison, the completely unsupervised feature-hmm baseline accuracy on the universal pos tags for english is 79.4, and goes up to with a treebank dictionary. the paper proposes a graph - based approach to pos taggers for languages which do not have any annotated data, but have translations into a resource-rich language. our method does not assume any knowledge about the target language across eight european languages, our approach results in an average absolute improvement of over a state-of-the-art baseline, and over vanilla hidden markov models induced with the expectation maximization algorithm. this paper proposes a new model for pos taggers in languages for which no labeled resources are available. the model is based on the feature-hmm of berg-kirkpatrick et al., which is a generalization of the traditional hmm model.", "1001": "recurrent neural networks ( rnns) have had considerable success in classifying and predicting sequences. we demonstrate that rnns can be effectively used in order to encode sequences and provide effective representations. the methodology we use is based on fisher vectors, where the rnns are the generative probabilistic models and the partial derivatives are computed using backpropagation. state of the art results are obtained in two central but distant tasks, which both rely on sequences: video action recognition and image annotation. we also show a surprising transfer learning result from the task of image annotation to the task of video action recognition. this paper proposes a novel pooling technique that takes a multiset of vectors and computes its mean : v 1n n i1 xi. clearly, the vector v that results from the pooling is in xi. this pooling technique takes a multiset of vectors , x x1, x2, , xn r d, and computes its mean : v 1n n i1 xi. the rnn is trained to predict the next element in a sequence, given the previous elements. given a sequence of input vectors x, the rnn is trained to predict the next vector in the sequence, i.e., the sequence y the output layer of the network is a fully-connected layer, the size of which would be d, i.e., the dimension of the input vector space. this special element is used to denote the beginning of the input sequence, and we use xstart throughout this paper. the rnn is trained to predict , at each time step i , the next element xi1 of the sequence, given the previous elements x0, ..., xi. therefore, given the input sequence, the target sequence would be : y ( x1 , x2, ... xn) in this paper , we present a new method for classifying video sequences . the method is based on a probabilistic model which predicts the sequence u ( w1 , w2 , ... , wn) from the sequence x ( x0, x1 , denote by m the size of our symbol alphabet, i.e. , the number of unique symbols in the input sequences, i.e. , the cross-entropy loss at time step i is derived from the probability which rnn gives to j th symbol at time step i. the loss function for the training of the rnn is the cross-entropy loss. after the rnn is trained, it is ready to be used as a feature vector extractor for new sequences. the classification application is applicable for predicting a sequence of symbols w1 , w2 , ... , wn that have matching vector representations r ( w1 , w2 , ... , r ( wn) xn the rnn predicts the sequence u ( w1 , w2 , ... , r ( wn) xn this paper presents two network alternatives for the image-sentence retrieval tasks : classification and regression. a sentence, being an ordered sequence of words, can be represented as a vector using the rnn-fv scheme. after each rnn epoch, we extract the rnn-fv representation as described above, we extract the rnn-fv representation as described above, we train a linear svm classifier on the training set and evaluate the performance on the validation set. the early stopping point is chosen at the epoch with highest recognition accuracy on the validation set. after choosing our model this way, we train an svm classifier on all training samples and report our performance on the test set. the training data may be any large set of sentences. these sentences may be extracted from the dataset of a specific benchmark, or, in order to obtain a generic representation, any external corpus, e.g., wikipedia, may be used. the two network alternatives are explored: classification and regression. in this paper, we propose a new classification method based on the regularized cca (regularized cca) algorithm. the regularized cca algorithm 47, where the regularization parameter is selected based on the validation set, is used to match the sentence rnn-fv representation with the sentence rnn-fv representation. in the shared cca space, the cosine similarity is used. not shown is the performance obtained when using the activations of the rnn as a feature vector. for matching images and text, each image is represented as a 4096-dimensional vector extracted using the 19-layer vgg. for gmm-fv, the only parameter is k, which is the number of components in the mixture. the state of the art on the bidirectional image and sentence retrieval task is ucf101 and hmdb51. in the bidirectional image and sentence retrieval task, we show that rnn-fv outperforms ucf101 and hmdb51. this paper introduces a novel fv representation for sequences that is derived from rnns. the proposed representation is sensitive to the element ordering in the sequence and provides a richer model than the additive bag model typically used for conventional fvs. the proposed representation surpasses the state-of-theart results for video action recognition on two challenging datasets. when used for representing sentences, the rnnfv representation achieves state-of-theart or competitive results on image annotation and image search tasks. since the length of the sentences in these tasks is usually short and, therefore, the ordering is less crucial, we believe that using the rnn-fv representation for tasks that use longer text will provide an even larger gap between the conventional fv and the rnn-fv . the paper proposes a novel approach for fv representation of sequences using a recurrent neural network ( rnn). the paper explores two different approaches for training the rnn for the image annotation and image search tasks. one is based on training a regression problem, and the other on training a classification problem. the rnn-fv is capable of encoding the sequence properties, and as underlying features, we rely on video encodings that are based on single frames or on fixed length blocks of frames. word embedding a word was represented either by word2vec, or by the gmmhglmm representation of 18, projected to a 300d sentence to vgg-encoded-image cca space. the vgg pipeline is cropped in ten different ways into by pixel images, the center, and their xaxis mirror image. the mean intensity is then subtracted in each color channel and the resulting images are encoded by the network. the rnn model consists of three layers: a 200d fullyconnected layer units with leaky-relu activation ( 0.1) , a 200-units long short-term memory ( lstm) layer, and a 500d linear fullyconnected layer. when training the rnn for regression, the same 300d input is used, followed by an lstm layer of size the output layer, in this case, is fullyconnected, where the ( 300 dimensional) word embedding of next word is predicted. the rnn-fv representation surpasses the state-of-the-art results for video action recognition on two challenging datasets. a transfer learning result from the image annotation task to the video action recognition task was shown. the con-ceptual distance between these two tasks makes this result both interesting and surprising.", "1002": "the rate of publications of scientific papers is increasing and it is almost impossible for re- searchers to keep up with relevant research. currently, no large- scale training data is available for the task of scientific paper summarization. in this paper, we propose a novel method that automatically generates summaries for scientific papers , by utilizing videos of talks at scientific conferences. we hypothesize that such talks constitute a coherent and concise description of the papers of content, and can form the basis for good summaries. we collected papers and their corresponding videos, and created a dataset of paper summaries. a model trained on this dataset achieves similar performance as models trained on a dataset of summaries created manually. in addition, we validated the quality of our summaries by human experts. alignment between spo- ken words and sentences in the paper, assuming the following generative process: during the talk, the speaker generates words for describing ver- bally sentences from the paper, one word at each time step. thus, at each time step, the speaker has a single sentence from the paper in mind, and produces a word that constitutes a part of its ver- bal description. then, at the next time-step, the speaker either stays with the same sentence, or moves on to describing another sentence, and so on. thus, given the transcript, the number of words uttered to describe each sentence can serve as importance score, in- dicating the amount of time the speaker spent de- scribing the sentence. this enables to control the summary length by considering only the number of words uttered to describe each sentence. in this paper, we propose a new method for paper summarization called hmm ( hmm stands for speaker matrix matrix matrix of transition probabilities) . this matrix is used to model the speaker matrix of the paper , and the transitions between any two sentences in the paper. we propose a novel automatic method to gener- ate training data for scientific papers summariza- tion, based on conference talks given by authors. we show that a model trained on our dataset achieves the competitive results compared to models trained on human generated summaries, and that the dataset quality satisfies human experts. in the future, we plan to study the effect of other video modalities on the alignment algorithm. we use an hmm to model the assumed genera- tive process: during the talk, the speaker generates words for describing ver- bally sentences from the paper, one word at each time step. given the transcript, we aim to retrieve those source sentences and use them as the sum- mary. this enables to control the summary length by considering only the most most im- portant sentences up to some threshold. moreover, our approach can generate sum- maries of various lengths.", "1003": "emotion detection from text has become a popular task due to the key role of emotions in human-machine interaction. current approaches represent text as a sparse bag-of-words vector, where each vector entry corresponds to the presence of a speci c feature ( such as n-grams, punctuation and other) as reported recently by 11, deep learning is a promising approach for solving nlp tasks including text classi cation. while the aforementioned approach utilizes bow representation and linear classi ers, neural network methods are based on dense vector representations of text samples ( word embedding) and are nonlinear. such word embedding representation captures syntactic and semantic knowledge, which can improve the emotion detection task. generating high quality word vectors requires large-scale data and computing power. when generation is not an option, one can utilize pre-trained representations; the most popular pre-trained representations are based on word2vec and glove algorithms, and were trained on large corpora. classi ers ( a binary classi er for each emotion), typically svm 19 or logistic regression 32, using textual features such as n-grams, lexicon based, and pos features. forgues used pretrained word vectors and a linear classi er to classify user intents in dialog systems, however their task and methodology is di erent than ours. we propose a novel classi er that is based on di erent document representation for each emotion. word ( and hence its weight ai) is di erent for each emotion. this is a novel embedded document representation method, and as detailed in section 5, it is superior in comparison to the other representation methods we experimented with. we experimented with the following ve emotion detection datasets from di erent domains: isear contains labeled sentences where participants who have di erent cultural backgrounds reported experiences and reactions for seven emotions. semeval contains newspaper headlines labeled with the six ekman emotions by six annotators. for our experiments, we considered the most dominant emotion as the headline label as in fairy tales, labeled with ve emotions by six annotators. blog posts consists of emotion-rich sentences collected from blogs labeled with emotions by four annotators. isear contains labeled sentences where participants who have di erent cultural backgrounds reported experiences and reactions for seven emotions. this work studied the use of pretrained word vectors for emotion detection. we presented a novel method for representing document as a dense vector based on the importance of the document s terms and the importance of the document s terms in respect to classi cation. our results show that an ensemble that combines bow embedded representations using our class method, outperforms previous approaches for domain-speci c datasets. in comparison to other deep learning methods, our approach ts a small number of model parameters and requires little computing power. for future work we plan to investigate the use of deep learning models trained on domain adapted pseudo-labeled largescale datasets. current approaches represent text as a sparse bag-of-words vector. in this work, we propose a new approach that utilizes pre-trained, dense word embedding representations. we introduce an ensemble approach combining both sparse and dense representations. for example, cbow representation for glove source showed a improvement in f1-score relative to word2vec. also, the class method we 2url/ 3url/ 4url 5url/ proposed outperformed the other embedded document representation methods.", "1004": "in this paper, we show that, in addition to text based turn features, dialogue features can significantly improve detection of emotions in social media customer service dialogues and help predict emotional techniques used by customer service agents. the analysis of emotions in customer support conversations can take two applications: ( 1) to discern and compute quality of service indicators and ( 2) to provide real-time clues to customer service agents regarding the cus-us.pdf tomer emotion expressed in a conversation. a possible application here is recommending to customer service agents what should be their emotional response ( for example, in each situation, should they apologize, should they thank the customer, etc.) to automatically detect emotions being expressed and, second that it is possible to predict the emotional technique that is likely to be used by a human agent in a given situation. this analysis reflects our ultimate goal: to enable a computer system to discern the emotions expressed by human customers, and to develop computerized tools that mimic the emotional technique used by a human customer service agent in a particular situation. we see the main contributions of this paper as follows: ( 1) to our knowledge, this is the first research focusing on automatic analysis of emotions expressed in customer service provided through social media. ( 2) this is the first research using unique dialogue features (e.g. , emotions expressed in previous dialogue turns by the agent and customer , time between dialogue turns) to improve emotion detection. ( 3) this is the first research studying the prediction of the agent emotional technique to be used in the response to customer turns. this paper proposes a novel method for emotion classification in written dialogues. the first objective of our work is to detect emotions expressed in customer turns and the second is to predict the emotional technique in agent turns. while both classifiers work at the level of turns, i.e., classify the current turn to emotions ex- pressed in it, they are inherently different. when detecting emotions in customer turns, the turn s content is available at classification time ( as well as the history of the dialogue) - meaning, the system must now understand what is the emotion expressed. examples of emotions being expressed are not available during classification time, but only the agent action and the history of the dialogue since the agent did not respond yet. this difference stems from the fact that in order to train an automated service agent to respond, the agent based on customer s emotional technique needs to be computed before the agent generates its response sentence. the goal of this paper is to classify agent and customer turn(s) in social media. the paper is divided into two parts. in the first part, the paper is divided into two parts. the goal of this paper is to classify dialogue acts by using a kth-order hidden markov model ( svm-hmm) and conditional random fields (cfd) classifiers. the svm-hmm classifier generates models that are isomorphic to a kth-order hidden markov model. under this model, dependency in past classification results is captured internally by modeling transition probabilities between emotion states. since emotions expressed in customer and agent turns are different, we treated them as different classification tasks ( like in our previous approach) and trained a separate classifier for each emotion. for turn ti, we considered it to express emotion e if tag ( e, ti) where tag ( e, t) is the average judges t tag value of e in t. this process generated the class sizes detailed in table dialogue topic tagging was converted to binary features representing the top-2 selected topics. the temporal response time values were translated to low/medium/high categorical values according to their relation to the 33-th and 66th percentiles. the taxonomy is based on ( zomer and voss, 2010) this paper proposes two classification tasks and two dialogue models that predict the emotional technique used by the support service agent. first tested the classification results for all possible history sizes ( given that that that maximum dialogue size in our dataset is 8) and evaluated them as detailed above. we used the context of the dialogue to extract informative features that we refer to as dialogue features. using these features for emotion classification in written dialogues is novel, and as our experimental results show, it improves performance compared to a model based only on features extracted from the turn s text. we treated these two objectives as two classification tasks. a feature can be global, namely its value is constant across an entire dialogue or it can be a local, meaning that its value may change at each turn. each turn ti is a tuple consisting of turn number, timestamp, content where turn number represents the sequential position of the turn in the dialogue, and content is the textual message. the goal of this paper is to predict the agent turn emotion and the customer turn emotion. the paper proposes two models for predicting the agent turn emotion and the customer turn emotion. the first model is svm, which is an svm classifier that generates models that are isomorphic to a kth-order hidden markov model. the second model is svm-hmm dialogue model, which is an svm dialogue model that generates models that are isomorphic to a kth-order hidden markov model. for predicting the agent turn emotion, the svm dialogue model obtained slightly better results than svm-hmm dialogue model, and reached a macro and micro average f1-score improvements over all dialogues of and 43.5, respectively. these results emphasize the differences between the svm dialogue and svm-hmm dialogue models. for customer turn emotion detection, the svm-hmm dialogue model performed better than the svm dialogue model, and reached a macro and micro average f1-score improvements over all dialogues of and 11.7, respectively.", "1005": "few-shot learning ( fsl) is a topic of rapidly growing interest. typically, in fsl a model is trained on a dataset consisting of many small tasks ( meta-tasks) and learns to adapt to novel tasks that it will encounter during test time. however, little attention has been given to explicitly optimizing the architectures for fsl, nor to an adaptation of the architecture at test time to particular novel tasks. in this work, we propose to employ tools inspired by the differentiable neural architecture search ( d-nas) literature in order to optimize the architecture for fsl without over-fitting. additionally, to make the architecture task adaptive, we propose the concept of met controller. these modules are added to the model and predict optimal network connections for a given novel task. using the proposed approach we observe state-of-art results on two popular few-shot benchmarks: miniimagenet and fc100. the architecture in task dependent manner to accommodate for novel tasks also has not been explored. in this work, we build our few-shot task-adaptive architecture search upon a technique from d-nas ( adversarial darts). our goal is to learn a neural network where connections are controllable and adapt to the few-shot task with novel categories. to make our architecture task adaptive so it would be able to quickly rewire for each new target task. to this end, we employ a set of small neural networks, met controllers, responsible for controlling the connections in the dag given the current task. the metadapt controllers adjust the weights of the different operations, such that if some operations are better for the current task they will get higher weights, thus, effectively modifying the architecture and adapting it to the task. in this work, we show how to learn a specialized backbone architecture that would facilitate this adaptability, as well as meta-learn to become capable of adapting that architecture itself to the task, thus going beyond the only adaptation of all previous metalearning approaches. in bf3s auxiliary self-supervision tasks are added, such as predicting image rotation or patch location. in robust-dist first an ensemble of up to models is learned, so each model by itself can not overfit the data. then, the the the final model is distilled from all those models. notably, our method which also deals with training large architecture without over-fitting is orthogonal to these two approaches. it is likely that further improvement can be achieved by combining these methods with our previous meta-learning methods. notably, in all previous meta-learning approaches, only the parameters of a ( fixed ) neural network are optimized in order to become adaptable ( or partially adaptable) to novel few-shots. by that, they managed to accelerate the search process. metadapt is a set of controllers that predict the task-adapted coefficients as a function of the current task. they are responsible for predicting , given a few-shot task, the best way of adapting the mixing coefficients ( ( i, j) o let ( i, j) be the vector of all ( i, j) o we use resnet9 followed by a single task-adaptable block with nodes ( v 4) in our experiments, resulting in about times more parameters compared with the original resnet12 ( due to large set of operations on all connections combined). the list of search space operations used in our experiments is provided in table this list includes the zero-operation and identity-operation that can fully or partially ( depending on the corresponding ( i, j) o) cut the connection or make it a residual one ( skip-connection) . each feature map xi in the block is connected to all previous maps by setting it to be : xi ji o ( j, i) ( xj) . in this paper, we propose a new method to train a large neural network with weighted connections that are then pruned to form the final chosen architecture. it has been shown, in the case of architecture search, that it is possible to learn an architecture on a smaller dataset, where the objective is to train a large neural network with weighted connections that are then pruned to form the final chosen architecture. in this paper , we propose a new approach to few-shot architecture search called metadapt. it is based on stochastic neural architecture search ( snas) where each edge is a weighted-sum of its operations according to i, j contrarily, in snas i, j are treated as probabilities of a multinomial distribution and at each iteration a single operation is sampled accordingly. so at each iteration only a single operation per edge affects the classification outcome and only this operation is be updated in the gradient descent backward step. a recent approach suggested for architecture search is stochastic neural architecture search ( snas 65) . metadapt is a few-shot learning approach that enables meta-learned network architecture that is adaptive to novel few-shot tasks. the proposed approach effectively applies tools from neural architecture search ( nas) literature in order to learn adaptive architectures. these tools help over-fitting to extremely small data of the few-shot tasks and mitigate the domain shift between the training set and the test set. we demonstrate that the proposed approach successfully improves state-of-the-art results on two popular few-shot benchmarks, miniimagenet and fc100, and carefully ablate the different optimization steps and design choices of the proposed approach. some interesting future work directions include extending the proposed approach to progressively searching the full network architecture ( instead of just the last block), applying the approach to other few-shot tasks such as detection and segmentation, and researching into different variants of task-adaptivity including global connections modifiers and inter block adaptive wiring. this is also referred to as meta-learning. another topic closely related to meta-learning with a lot of interest in the community is neural architecture search ( nas) , automatically finding optimal architecture instead of engineering it manually. additionally, to make the architecture task adaptive, we propose the concept of metadapt controllers. this paper proposes a new approach for few-shot classification that adapts the architecture at test-time to a specific novel task. in this approach, the architecture of the block is built from feature maps v xi that are linked by mixtures of operations. the input feature map to the block is x0 and its output is xv a mixed operation, o ( i, j) o ( i, j) o ( x) oo exp ( ( ( i, j) o) o ( x) oo exp ( ( ( i, j) o) o ( x) oo exp ( ( ( i, j) o) o ( x) oo exp ( ( i, j) o) o ( x) oo exp ( ( i, j) o) o ( x) oo exp ( ( ( i, j) o) o ( x) oo exp ( ( ( i, j) o) o ( x) oo exp ( ( i, j) o) o ( x) oo exp ( ( i, j) o) o ( x) oo exp ( ( i, j) o ( x) oo exp ( ( i, j) o ( x) oo exp ( in this work we have proposed metadapt, a few-shot learning approach that enables meta-learned network architecture that is adaptive to novel few-shot tasks. the proposed approach effectively applies tools from the neural architecture search ( nas) literature, extended with the concept of metadapt controllers, in order to learn adaptive architectures.", "1006": "in this paper, we outline an approach to detecting such egregious conversations, using behavioral cues from the user, patterns in agent responses, and useragent interaction. using logs of two commercial systems, we show that using these features improves the detection f1-score by around over using textual features alone. in addition, we show that those features are common across two quite different domains and , arguably, universal. the goal of this work is to reliably detect egregious conversations between a human and a virtual agent. we treat this as a binary classification task, where the target classes are egregious and nonegregious. while we are currently applying this to complete conversations, some of the features examined here could likely be used to detect egregious conversations as they were unfolding in real time. to perform detection of egregious conversation, features from both customer inputs and agent responses are extracted, together with features related to the combination of specific inputs and responses. in addition, some of these are contextual, meaning that they are dependent on where in the conversation they appear. using this set of features for detecting egregious conversations is novel, and as our experimental results show, improves performance compared to a model based solely on features extracted from the conversation s text. this paper proposes a novel approach to address the question of whether or not a virtual agent can reliably detect the intent of each customer . as typically implemented , the virtual agent is trained to reliably detect the intent of each customer s utterance meaningfully. accurate intent detection is thus a fundamental characteristic of well-trained virtual agents, and incorrect intent analysis is reported as the leading cause of user dissatisfaction ( sarikaya , 2017 ) . however, since svm, neural network, etc., is often used to detect intents, its probabilistic behavior can cause the agent to repeat the same or semantically similar response over and over again, despite the user s same attempt to rephrase intent. such agent repetitions lead to an unnatural interaction ( kluwer, 2011) . to identify the agent s agent s similarity, we used the positive sentiment score ( neg emo) as a filter for other customer features, such as high positive emotions capture different styles of the agent, or indicate that the customer is somewhat satisfied ( rychalski and hudson, 2017 ) . in this paper, we propose a classification model that is based on a similarity analysis. the similarity analysis is based on the similarity between the agent s response and the customer s turn. in this case, a pair may contain a turn in which the customer expressed negative power judgements and received a response of not trained by the agent. in this case, we would leverage the two analyses: a low score may indicate a poor interaction, which might lead to the agent becoming egregious. thus, a low score may indicate a poor interaction, which might lead to the agent becoming egregious. we trained a binary svm with a linear kernel . a feature vector for a sample in the training data is generated using the scores calculated for the described features, where each feature value is a number between 0,1. after the model was trained, after being transformed to a feature vector in the same way a training sample is transformed. this process generated the egregious class sizes of ( 8.6) and ( 8.6) and have experience in designing conversational agents systems. this paper proposes an egr model for the classification task. the egr model is compared to a text-based model in terms of accuracy and recall. the goal of this work is to give developers of automated agents tools to detect and then solve problems cre- ated by exceptionally bad conversations. in this context, future work includes collecting more data and using neural approaches (e.g., rnn, cnn) for analysis, validating our models on a range of domains beyond the two explored here. the goal of this paper is to detect egregious conversations in customer care systems. an ineffective interaction requires the expenditure of relatively effort from the user with little return on the investment these efforts can appear as behavioral cues in the large customer inputs and include emotions, repetitions, and more. in examining the conversation logs, we noticed that it is not unusual to find a customer asking to be transferred to a human agent. such a request might indicate that the virtual agent is not providing a satisfactory service. moreover, even if there are human agents, they might not be available at all times, and thus, a rejection of such a request is sometimes reasonable, but might still lead to customer frustration. in order to analyze the emotions that customers exhibit in each turn, we utilized the ibm tone analyzer service, the available publicly online7 . in order to analyze the emotions that customers exhibit in each turn, we infer emotions such as frustration, sadness, anger, etc. in order to analyze the emotions that customers exhibit in each turn, we focused on negative emotions ( neg emo) to identify turns with a negative emotional peak ( i.e., single utterances that carried high negative emotional state, as well as to estimate the aggregated negative emotion intensity throughout the conversation. the goal of this paper is to show how it is possible to detect egregious conversations (i.e., conversations that are extraordinarily bad in some way, those conversations which are extraordinarily bad in some way, those conversations which are too short to be meaningful since the customer never replied or provided more details about the issue at hand). as explained, the goal of this paper were difficult in this context, future work includes collecting more data and using neural approaches for analysis, validating cnn. in this context, future work includes collecting more data and using neural approaches for analysis, validating cnn.", "1007": "we present an analysis into the inner workings of convolutional neural networks ( cnns) for processing text. cnns used for computer vision can be interpreted by projecting filters into image space, but for discrete sequence inputs cnns remain a mystery. we aim to understand the method by which the networks process and classify text. we examine common hypotheses to this problem: that filters, accompanied by global max-pooling serve as ngram detectors. we show that filters may capture several different semantic classes of ngrams by using different activation patterns, and that global max-pooling induces behavior which separates important ngrams from the rest. finally, we show practical use cases derived from our findings in the form of model interpretability ( explaining a trained model by deriving a concrete identity for each filter, bridging the gap between visualization tools in vision tasks and nlp) and prediction interpretability ( explaining predictions) . this paper proposes a new method for text classification based on convolutional neural networks (cnns ) and softmax ( wp ) . the method is based on max-pooling across the ngram dimension , where each ngram is represented by a max-pooled vector (m ) , where m is the dimension of the convolutional network (cnn) and n is the dimension of the max-pooled vector (p ) , where p is the number of ngrams in the max-pooled vector , and m is the dimension of the max-pooled vector (p ) , where m is the dimension of the max-pooled vector (p ) , where m is the dimension of the max-pooled vector (p ) , where m is the dimension of the max-pooled vector (p ) , where m is the dimension of the max-pooled vector (p ) , where m is the dimension of the max-pooled vector (p ) , where m is the dimension of the max-pooled vector (p ) , where m is the dimension of the max-pooled vector (p )  this paper proposes a new method for training a network classifier on a given set of filters. in the paper, the paper proposes a method for training a network classifier on a given set of filters. this paper presents an adversarial model that can be used to find adversarial examples that cause a trained model to misclassify. the model can be used to find adversarial examples that cause a trained model to misclassify. this paper proposes a clustering algorithm that identifies the activations of ngrams in the cnn model. the clustering algorithm identifies two clusters: one primarily containing ngrams of the pattern det intensity-adverb-word, while the second contains ngrams that begin with phrases like go wrong.7 the centroids for these clusters capture the activation patterns well: low-medium-high and high-highlow for clusters and respectively. to summarize, by discarding noisy ngrams which do not pass the filter s threshold and then clustering those that remain according to their slot activation patterns, we arrived at a clearer image 6intuitively, we arrived at a clearer image 6intuitively, we can think of the sampling noise as the ngram embeddings, and the probability distribution as defined by the filter coverage as defined by the filter activation patterns. each cluster corresponds to a slot activation pattern. cnns have been shown to perform well on text classification tasks. in this paper, we show that cnns are not homogeneous. we show that cnns are not homogeneous. we also show that filters sometimes opt to assign negative values to certain word activations in order to cause the ngrams which contain them to receive a low score despite having otherwise highly activating words. finally, we use these findings to suggest improvements to model-based and predictionbased interpretability of cnns for text. we decompose the ngram score into word-level scores by treating the convolution of a filter as a sum of word-level convolutions, allowing us to examine the word-level composition of the activation. specifically, by maximizing the word-level activations by iterating over the vocabulary, we observed that filters do not maximize activations at the word-level, but instead form slot activation patterns that give different types of ngrams similar activation strengths. this provides empirical evidence that filters are not homogeneous. this paper presents an analysis into the inner workings of convolutional neural networks ( cnns) for processing text. this paper addresses the question of whether a given filter is homogeneous and specializes in detecting a specific class of ngrams. we challenge this view and show that filters often specialize in multiple distinctly different semantic classes by utilizing activation patterns which are not necessarily maximized. we also show that filters may not only identify good ngrams, but may also actively supress bad ones.", "1008": "a summary generated by editnet may include sentences that were either extracted , abstracted or of both types. moreover, per considered sentence, editnet may decide not to take either of these decisions and completely reject sentence. using the cnn/dailymail dataset we demonstrate that editnet s summarization quality is highly competitive to that obtained by both the state-of-the-art abstractive-only and extractive-only baselines. in order to make an educated decision, the editor considers both sentence representations esi and asi as its input, together with two additional auxiliary representations. given the four representations as an input, the editor s decision for sentence si s is implemented using two fully -connected layers. such a network architecture allows to capture various complex interactions between the different inputs. for example, the network may learn that given the global context, one of the sentence versions may allow to produce a summary with a better coverage. as another example, based on the interaction between both sentence versions with either of the local or global contexts ( and possibly among the last two), the network may learn that both sentence versions may only add superfluous or redundant information to the summary, and therefore, decide to reject both. this paper introduces a novel soft labeling approach for extracting and abstracting the contextual information of a text. given a text input with l extracted sentences, we utilize a given summary quality metric r (s) which can be used to evaluate the quality of any given summary s. we next explain how each soft-label y ( i) is estimated. given text s ( with l extracted sentences) , let ( 1 , l) denote its editing decisions 1such a representation is basically a combination of a temporal convolutional model followed by a bilstm encoder. 2the first and last chunks would only have two consecutive sentences. we define the following soft crossentropy loss: l ( s) l sisie, a, r y ( i) log p ( i) , where , for a given sentence si s, y ( i) denotes its soft-label for decision. we next explain how we train the editor using a novel soft labeling approach. we conclude this section with the description of how we train the editor using a novel soft labeling approach. this demonstrates that, editnet has a high capability of utilizing abstraction, while being also able to maintain or reject the original extracted text whenever it is estimated to provide the best benefit for the summarys quality.", "1009": "this paper presents a high dimensional encoded phonetic similarity algorithm for chinese. the encodings are learned from annotated data to separately map initial and phonemes into n-dimensional coordinates. pinyin phonetic similarities are then calculated by aggregating the similarities of initial , final and tone. dimsim demonstrates a 7.5x improvement on mean reciprocal rank over mean phonetic similarity approaches. this paper proposes a supervised learning approach to learn n dimensional encodings for finals and initials where n can be easily extended from one to two or higher dimensions. the learning model derives accurate encodings by jointly considering pinyin linguistic characteristics, such as place of articulation and pronunciation methods, as well as high quality annotated training data sets. we compare dimsim to double metaphone ( dm) , minimum edit distance ( med) and aline demonstrating that dimsim outperforms these algorithms by 7.5x on mean reciprocal rank, 1.4x on precision and 1.5x on recall on a real world dataset. a package release of the implemented algorithm and a constructed dataset of chinese words with phonetic corrections.2 dimsim generates ranked candidate words with similar pronunciation to a seed word. this paper presents a supervised machine learning approach that uses pinyin linguistic characteristics combined with manually labeled data sets of phonetic similarity. the training data sets consist of word pairs that highlight a pair of initials ( or finals), and are used as the context for an annotator-provided phonetic similarity score. the set of initials ( or finals) is then mapped to the n-dimensional encodings by minimizing the difference between the resulting pairwise distances, and the distances obtained from the training data sets. generating similar word pairs phonetically similar word pairs are used to create annotations representing the phonetic similarity of a pair of initials , or finals. chinese has pairs of initials and pairs of finals. manually annotating each pair similarity requires a very large number of examples: assuming ten or twenty word pairs are provided as context for each pair, the task quickly blows up to eighteen thousand annotations. leveraging known pinyin linguistic characteristics can improve the accuracy of our model and reduce the size of the annotation task. the aim of this paper is to generate word pairs whose pinyins only differ in these pairs. for each word pair, the annotators give a label on a point scale representing their agreement. equation equation inverts the labels so that the output can be used as a distance metric ( phonetically similar initials or finals are closer together, and scales the result to more accurately measure phonetic similarities. parameters a and b are set and by default, but we also show that the performance of our method is not sensitive to the parameter settings. the final goal is to map each initial ( or final) to an ndimensional point. based on the structured structured of table 2, we intuit that extending beyond one dimension will yield more accurate encodings. figures and visualize the computed encodings of initials when setting the computed encodings of initials to be and 0.54, representing the inter-annotator agreement. for each word pair, we use equation to calculate the distance with the average value of labels across the annotators. this paper studies the impact of varying the pairwise phonetic distance between a word and a chinese pinyin dictionary (dict) on the accuracy and recall of the generated candidates. a larger th generates more candidates, increasing recall while decreasing precision.3 finally, we output the candidates ranked in ascending order by similarity distance. since downstream applications will only consider a limited number of candidates in practice, we evaluate precision via a manual annotation task on the top-ranked candidates generated by each approach. dm considers word spelling, pronunciation and other miscellaneous characteristics to encode the word into a primary and a secondary code. dm as one of the baselines is known to perform poorly at ranking the candidates since only two codes are used. we therefore use our method to rank the dm-generated candidates, to create a second baseline, dm-rank.4 the third baseline, aline, measures phonetic similarity based on manually coded multi-valued articulatory features weighted by their relative importance with respect to feature salience. dimsim is an improved phonetic similarity algorithm that encodes the phonetic distance between a pair of words as a pair of pairs of pairs of pairs of one- and two-dimensional encodings. there is a plethora of work focusing on phonetic similarities between words and characters these algorithms encode words with similar pronunciation into the same code. these algorithms fail to capture chinese phonetic similarity since pinyin has its own specific characteristics, which do not easily map to english, for determining phonetic similarity. dimsim generates phonetically similar candidate words based on learned encodings that capture the pronunciation characteristics of pinyin initial, final, and tone components. using a real world dataset, we demonstrate that dimsim effectively improves mrr by 7.5x, recall by 1.5x and precision by 1.4x over existing approaches. this paper presents dimsim, a learned ndimensional phonetic encoding for chinese along with a phonetic similarity algorithm, which uses the encoding to generate and rank phonetically similar words. dimsim demonstrates a 7.5x improvement on mean reciprocal rank over the state-of-the - art. this paper proposes a new method to learn chinese word encodings based on annotators. the model aims to minimize the sum of the absolute differences between the euclidean distances of component pairs and the average distances obtained from the annotated training data across all pairs for initials ( or finals) c. the parameters a and b are set and by default, but we also show that the performance of our model is not sensitive to the parameter settings. we also incorporate a penalty function, p, for pairs deviating from the manually annotated distance so that more phonetically similar pairs are penalized more highly. we observe that when n 2, the locations of initial coordinates align well with table 2, . in particular, the twelve groups are clustered in a pattern that is defined in section for example, bp, gk, jqx are separated into different clusters. however, while table indicated the basic clusters for the initials, our learned model goes further than table by actually quantifying the inter- and intra-cluster similarities. dimsim is a chinese language counterpart of the named entity translation algorithm soundex ( archives and administration, 2007 ) . the original motivation for this work was to improve the quality of downstream nlp tasks , such as named entity identification, text normalization and spelling correction. these tasks all share a dependency on reliable phonetic similarity as an intermediate step, especially for languages such as chinese where incorrect homophones and synophones abound.", "1010": "relation detection is a core component of many nlp applications including knowledge base question answering ( kbqa). although general relation detection1 methods are well studied in the nlp community, such studies usually do not take the end task of kbqa into consideration. as a result, there is a significant gap between general relation detection studies and kb-specific relation detection. first, in most general relation detection tasks, the number of target relations is limited, normally smaller than in contrast, in kbqa even a small kb, like freebase2m, contains more than 6,000 relation types. second, noticing 1in the information extraction field such tasks are usually called relation extraction or relation classification. that original relation names can sometimes help to match longer question contexts, we propose to build both relation-level and word-level relation representations. third, we use deep bidirectional lstms to learn different levels of question representations in order to match the different levels of relation information. finally, we propose a residual learning method for sequence matching, which makes the model training easier and results in more abstract ( deeper) question representations, thus improves hierarchical matching. relation extraction relation extraction recent research benefits a lot from the advancement of deep learning: from word embeddings to deep networks like cnns and lstms and attention models the above research assumes there is a fixed ( closed) set of relation types, thus no zero-shot learning capability is required. the number of relations is usually not large: the widely used ace2005 has 11/32 coarse/fine-grained relations; semeval2010 task8 has relations; tac- kbp2015 has relations although it considers open-domain wikipedia relations. all are much fewer than thousands of relations in kbqa. as a result, few work in this field focuses on dealing with large number of relations or unseen relations. deep bilstms have been widely used for prediction of word embeddings of question words (e.g. q q1, qn, qn) and word embeddings of relation words (e.g. episode, written, and relation names, series, when the target is a chain like in figure 1 ( b) ) . in this paper, we propose to use deep bilstms for prediction of word embeddings of question words (e.g. in this paper, we propose a new approach to the kbqa end task called hierarchical residual bilstm ( hr-bilstm) model. hr-bilstm is a hierarchical residual matching model ( hr -bilstm) that is based on the hierarchical residual bilstm ( hr-bilstm) model. to a relation detector to score all the relations r re that are associated to the entity e in the kb.4 because we have a single topic entity input in this step, we do reformating following question: we replace the candidate e, the entity mention in 4note that the number of entities and the number of relation candidates will be much smaller than those in the previous step. this helps the model better distinguish the relative position of each word compared to the entity. we use the hr-bilstm model to predict the score of each relation r re: srel ( r; e, q) hr-bilstm is a combination of two bilstms (both on words) with residual connections between their hidden states. the main idea is to use the hierarchical architecture to learn different levels of abstraction. we hypothesize that hr-bilstm is more than combination of two bilstms with residual connections, because it encourages the hierarchical architecture to learn different levels of abstraction. to verify this, we replace the deep bilstm with two single-layer bilstms with shortcut connections between their hidden states. this decreases test accuracy to it gives similar training accuracy compared to hr-bilstm, indicating a more serious over-fitting problem. in the experiments a two-layer bilstm converges to 94.99, even lower than the achieved by a single-layer bilstm. under our setting the twolayer model captures the single-layer model as a special case ( so it could potentially better fit the training data), this result suggests that the deep bilstm without shortcut connections might suffers more from training difficulty. kb relation detection is a key step in kbqa and is significantly different from general relation extraction tasks. we propose a novel kb relation detection model, hr-bilstm, that performs hierarchical matching between questions and kb relations. our model outperforms the previous methods on kb relation detection tasks and allows our kbqa system to achieve state-of-the -arts. for future work, we will investigate the integration of our hr-bilstm into end-to-end systems. in this paper, we propose a hierarchical recurrent neural network enhanced by residual learning which detects kb relations given an input question. our method uses deep residual bidirectional lstms to compare questions and relation names via different levels of abstraction. additionally, we propose a simple kbqa system that integrates entity linking and our proposed relation detector to make the two components enhance each other. our experimental results show that our approach not only achieves outstanding relation detection performance, but more importantly, it helps our kbqa system achieve state-of-theart accuracy for both single-relation and multi-relation qa benchmarks. this paper proposes a hierarchical bilstm ( hr-bilstm) model for the kbqa end task. the hr-bilstm model is used to score all relations in the kb that are associated to the entities in elk ( q) by taking into account the maximum overlapping sequence of characters between them. if the matching score is larger than a threshold ( tuned on training set), we will add the constraint entity c ( and rc) to the query by attaching it to the corresponding node v on the core-chain. the hr-bilstm model is used to predict the score of each relation r re : srel ( r; e; q) srel ( r; e; q) where is a constant parameter. for each question q, after generating a score srel ( r; e; q) for each relation using hr-bilstm, we use the top l best scoring relations ( rlq) to re-rank the original entity candidates.", "1011": "we propose a human-in-the-loop ( huml) dictionary expansion approach that employs a lightweight neural language model coupled with tight huml supervision to assist the user in building and maintaining a domain-specific dictionary from an input text corpus. the approach is based on the explore/exploit paradigm to effectively discover new instances ( explore) from the text corpus as well as predict new unseen terms not currently in the corpus using the accepted dictionary entries ( exploit). given an input text corpus and a set of seed examples, the proposed approach runs in two phases, explore and exploit, to identify new potential dictionary entries. the exploit phase tries to identify similar instances to the dictionary entries that are present in the input text corpus, while both cases may simply not occur. however, these phrases are likely to occur in future texts from the same source, and thus are important to include in any entity extraction. multiterm phrases are a challenge for word2 style systems as they need to be known prior to model creation. in this work, we adopt the glimpse computer/ human part- psb2016 is a recent benchmarking initiative on the problem url/ sharedtaskeval.html. experiments show that the system is more effective when receiving huml feedback after identified candidates, compared to receiving huml feedback after identified candidates, while both cases require equal amount of human effort. while completely automatic techniques are highly appealing they need to be fine-tuned for every new task. we propose a human-in-the-loop approach where the tuning is an integral part of the process, i.e. the human works in partnership with the statistical method to drive the semantic of the task effectively and efficaciously. for a surveillance application (e.g., drug side effects mentioned on twitter) it reduces how frequently a human needs to tune up the lexicon to make sure it is catching all relevant entity instances. for the experiments we use data from the healtcare domain, specifically tackling the problem of identifying adverse drug reactions in user generated data. as an input set of seed examples we compare the performance of the explore, exploit and the explore/exploit approaches for discovering new dictionary instances. this paper proposes an interactive dictionary expansion tool using a lightweight neural language model. it incorporates human feedback to improve performance and control semantic drift at every iteration cycle. the approach is based on the explore/exploit paradigm to effectively discover new instances ( explore) from the text corpus as well as predict new unseen terms not currently in the corpus using the accepted dictionary entries ( exploit) this paper proposes an interactive dictionary expansion tool using a lightweight neural language model. our algorithm is iterative and purely statistical, hence does not require any feature extraction beyond tokenization. the experiments showed high importance of tight huml integration on discovery efficiency.", "1012": "grounding of textual phrases, i.e., finding bounding boxes in images which relate to textual phrases, is an important problem for human-computer interaction, robotics and mining of knowledge bases, three applications that are of increasing importance when considering autonomous systems , augmented and virtual reality environments. for example, we may want to guide bottle on your left phrase such as autonomous system by using the plate in the top shelf. while those phrases pose significant challenges for present day textual grounding algorithms, as interpretation of those phrases requires an understanding of objects and their spatial-image relationships and provide interpretability. more specifically, deep net models are designed to extract features from given bounding boxes and textual data, which are then compared to measure their fitness. to obtain suitable bounding boxes, many of the textual grounding frameworks, such as 38, 15, make use of region proposals. this paper proposes an energy minimization approach for bounding box proposals. the approach is based on a set of image concepts like semantic segmentations, energy detections or image priors. all those concepts come in the form of score maps which we combine linearly searching for the bounding box containing the highest accumulated score over the combined score map. moreover, linear combination of score maps reveals importance of score maps for specific queries as well as similarity between queries such as skier , snowboarder. hence the framework that we discuss in the following is easy to interpret and extend to other settings. the search over a large number of bounding boxes allows us to retrieve an accurate bounding-box prediction for a given phrase and an image. importantly, by leveraging branch-and-bound techniques, we are able to find the global minimizer very effectively. in this paper, we propose a new approach to find the bounding box with lowest energy. the approach is based on a set of word priors and k2 geometric cues. for the top k1 words in the training set we construct word prior maps like the ones shown in fig. for the top k1 words in the training set we obtain probability maps for a set of class categories, i.e., a subset of the nouns of interest. to obtain the prior for a particular word, we search a given training set for each occurrence of the word. with the corresponding subset of image-text pairs and respective bounding box annotations at hand, we compute the average number of times a pixel is covered by a bounding box. to facilitate this operation, we scale each image to a predetermined size. the k2 geometric cues provide the aspect ratio and the area of the hypothesized bounding box y. note that the word priors and geometry features contain no information about the image specifics. to encode measurements dedicated to the image at hand, we take advantage of semantic segmentation and object detection techniques. in this paper, we show how to compute a lower bound e ( x, yj, w) on the energy for an output space, and to illustrate the conditions which guarantee convergence to the global minimum of the energy function. for the latter, we note that bounds on score maps for bounding box intervals can be computed by considering either the largest or the smallest possible bounding box in the bounding box hypothesis, y depending on whether the weight in wt is positive or negative and whether the feature mask contains only positive or negative values. intuitively , if the weight is positive and the feature mask contains only positive values, we obtain the smallest lower bound e ( x, y, w) by considering the content within the smallest possible bounding box. note that score maps do not necessarily contain only positive or negative numbers. however we can split the given score maps into two separate score maps ( i.e., one with only positive values, and another with only negative values) while applying the same weight. it is important to note that computation of the bound e ( x, yj, w) has to be extremely effective for the algorithm to run at a reasonable speed. however, computing the feature mask content for a bounding box is trivially possible using integral images. this paper proposes a novel approach for object detection and segmentation. we demonstrate a mechanism for grounding of textual phrases which provides interpretability, is easy to extend, and permits globally optimal inference. in contrast to existing approaches which are generally based on a small set of bounding box proposals, we efficiently search over all possible bounding boxes. we think interpretability, i.e., linking of word and image concepts, is an important concept, particularly for textual grounding, which deserves more attention. this paper presents a novel approach for textual grounding which is based on a deep net based model. the model is based on a set of image concepts, such as semantic segmentations, detections, and word priors. the search for this box can be solved via an efficient branch and bound 31st conference neural information processing systems ( nips 2017 ) textual grounding is an important but challenging task for human-computer interaction, robotics and knowledge mining. while those phrases pose significant challenges for present day textual grounding algorithms, as interpretation of those phrases requires an understanding of objects and images. based on those image concepts, which are represented as score maps, we formulate grounding as a search over all possible bounding boxes. the search for this box can be solved via an efficient branch and bound 31st conference neural information processing systems ( nips 2017 ) in this paper, we propose a novel approach for unsupervised learning of the parameters of a feature space. the method is based on the idea of learning a lower bound e ( x, yj, w) on the energy of the feature space. the lower bound e ( x, yj, w) is computed using a linear combination of word priors and accumulated segmentation masks.", "1013": "moment matching approaches for generative modeling are based on the assumption that one can learn the data distribution by matching the moments of the model distribution to the empirical data distribution. two representative meth- equal contribution. ods of this family are based on maximum mean discrepancy by using a specially designed objective function. we propose a simple but effective moment matching method that : ( 1) breaks away from the problematic min/max game completely; ( 2) does not use online learning of kernel functions; and ( 3) is very efficient with respect to both number of used moments and required minibatch size. our proposed approach, named generative feature matching networks ( gfmn) , learns implicit generative models by performing mean and covariance matching of features extracted from all convolutional layers of pretrained deep convnets. some interesting properties of gfmns include: ( a) the loss function is directly correlated to the generated image quality; ( b) mode collapsing is not an issue; and ( c) the same pretrained feature extractor can be used across different datasets. in this paper, we propose a new feature matching method based on moving averages of the difference of the means of the features extracted by the hidden layer from real and generated data. instead of computing the ( memory ) expensive feature matching loss in eq. 1, we keep moving averages of the difference of feature means ( covariances) at layer j between real and generated data. using these moving averages we replace the first term of the loss given in eq. 1, we can now rely on vj to get better estimates of the population feature means of real and generated data while using a small minibatch of sizen for a similar result using the feature matching loss given in eq. 1, one would need a minibatch of sizen for a similar result using the feature matching loss given in eq. 1 moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages moving averages gfmn is a generative moment matching network (gfmn) that performs mean and covariance matching in a pf space induced by a nonlinear kernel function ( dcnn) that is orders of magnitude larger than the ae latent code, and that we argued is universal in the image domain. gfmn is related to the recent body of work on mmd and moment matching based generative models 22 , 8 , 21 , 3, the closest to our method is the generative moment matching network autoencoder ( gmmnae) proposed in in gmmnae, the objective is to train a generator g that maps from a prior uniform distribution to the latent code learned by a pretrained ae, and then uses the frozen pretrained decoder to map back to image space. gfmn training: gfmns are trained with an adam optimizer; most hyperparameters are kept. gfmn is a feature extractor that can be used to generate images from dcnns. this paper presents a new approach to training implicit generative models through moment matching (gfmn) that uses a cross domain feature extractor and a loss function that only performs feature matching (vgg19 resnet18 ) . compared to recent adversarial mmd methods ( mmd gan) 21 , gfmn also presents significantly better results while avoiding the problematic min/max game. compared to recent learned moments (molm) 33, gfmn achieves better results than the method of learned moments (molm) 33, while using a much smaller number of features to perform matching. the best performing model from 33, molm1536, uses around million moments to train the cifar10 generator, while our best gfmn model uses around 850k moments/features only, almost 50x less. we achieve successful nonadversarial training of implicit generative models by introducing different key ingredients: ( 1 ) moment matching on perceptual features from all layers of pretrained neural networks; ( 2 ) a more robust way to compute the moving average of the mean features by using adam optimizer, which allows us to use small minibatches; and ( 3 ) the use of perceptual features from multiple neural networks at the same time. a feature map is universal if ( y) is dense in c ( z) for all z compact subsets of x.i.e a feature map is universal if ( y) c ( z) . a feature map is universal if ( y) is dense in c ( z) for all z compact subsets of x.i.e a feature map is universal if ( y) c ( z) the objective of this paper is to show that wgan-gp can learn to distinguish between real and fake images. this is a well - known issue with gan training where the training of the generator and discriminator must strike a balance. if a discriminator can distinguish perfectly between real and fake early on, the generator can not learn properly and the min/max game becomes unbalanced, having no good discriminator gradients for the generator to learn from, producing degenerate models. in this paper, we show that wgan-gp can learn to distinguish between real and fake images. the use of perceptual features ( pfs) in the context of learning implicit generative models through moment matching ( mm) is not well studied. more specifically, we propose a new effective mm approach that learns implicit generative models by performing mean and covariance matching of features extracted from pretrained convnets. gfmn is a generative moment matching network autoencoder ( gmmnae) that uses a dcganlike architecture in the generator. the generator is trained with a dcganlike architecture in the generator and then uses the frozen pretrained decoder to map back to image space. gfmns are trained with an adam optimizer (adam optimizer) that uses adam optimizer to compute the moving average of the mean features. gfmns are trained with an adam optimizer (adam optimizer) to perform mean and covariance matching in a pf space induced by a nonlinear kernel function ( a dcnn) that is orders of magnitude larger than the ae latent code, and that we argued is universal in the image domain. the discriminator, being pretrained on imagenet, can quickly learn to distinguish between real and fake images. this limits the reliability of the gradient information from the discriminator, which in turn renders the training of a proper generator extremely challenging or even impossible.", "1014": "recommender systems aim to present items with high utility to the consumers utility may be decomposed into form utility: the item is desired as it is manifested, and time utility: the item is desired at the given point in time 28; recommender systems should take both types of utility into account. for an item by comparing the time t since her most recent purchase within the item with the most recent purchase within the category and the item s underlying inter- duration d; larger value of d t may indicate that the item needs to be replaced, and she may be open to related recommendations. in contrast, larger value of d t may indicate that the item needs to be replaced, and she may be open to related recommendations. in this paper, we consider the problem of learning the time durations of items in the same category. the problem of learning a third- or fourth- order tensor x is to find a low - rank tensor x such that its frontal slice is a second- or third - order tensor ( matrix) and its frontal slice is a low - rank tensor x such that its frontal slice is a second- or third - order tensor ( matrix) and its frontal slice is a low - rank tensor x such that its frontal slice is a second- or third - order tensor ( matrix) and its frontal slice is a low - rank tensor x such that its frontal slice is a second- or third - order tensor ( matrix) and its frontal slice is a low - rank tensor x such that its frontal slice is a second- or third - order tensor ( matrix) and its frontal slice is a low - rank tensor x such that its frontal slice is a second- or third - order tensor ( matrix) and its frontal slice is a low - rank tensor x such that its frontal slice is a second- or third - order tensor ( matrix) and its frontal slice is a low - rank tensor x such that its frontal slice is a second- or third - order tensor ( matrix) this paper proposes a novel proximal gradient descent algorithm for nuclear norm minimization , where each gradient is approximately computed and the approximation error is upper bounded by a constant between zero and one. since each iteration of proximal gradient descent for nuclear norm minimization only requires a fixed number of iterations of randomized svd ( or equivalently, power iterations) using the warm start strategy, thus we have the following lemma. a proximal gradient descent algorithm can be applied to solve problem ( 6) within o ( nk2t mk2t p0k) time, where t is the number of iterations. the goal of this paper is to propose a demand-aware recommender for one-sided sampling ( daross for short) that is suitable for general e-, item recommendation mechanisms involving both durable and non durable goods. in order to generate the subsets, we randomly sample item categories for tmall dataset and select the users who have purchased at least items within these categories, leading to the purchase records of users and items. for each user pair ( u, i, t) in the test set, we randomly sample her purchase records as the training data, and use the remaining as the test data. for each purchase record ( u, i, t) in the test set, we evaluate all the algorithms on two tasks: ( i) category prediction, and ( ii) purchase time prediction, respectively. the algorithms m3f, pmf, and wr-mf are excluded from the purchase time prediction task since they are static models that do not consider time information. indeed, the learned inter-unlabeled nature of the data can also play an important role in applications more advanced than recommender systems, such as inventory management, operations management, and sales/ marketing management. we formulate it as a tensor norm minimization problem that seeks to jointly learn the form utility tensor and a vector of inter-purchase durations, and propose a scalable algorithm with a tractable time complexity. on two real-world datasets, tmall and amazon review, we show that our algorithm outperforms six state-of-the-art recommendation algorithms on the tasks of category, item, and purchase time predictions. in this paper, we study the problem of demand-aware recommendation. given a user s intention for an item by comparing the time utility since her most recent purchase within the item category cj until time k, the larger the value of d t, the less likely she needs this item. in contrast, the function h max ( 0, d t) may be employed to measure the underlying inter-purchase duration times of the r item categories. it is understood that the inter-purchase durations for nondurable good categories are large, while for durable good categories the inherent properties are small, or even zero. thus, a user might not purchase an item because she does not derive utility from it, or just because she was simply unaware of it or plans to buy it in the future. in this sense, the demand is mediated by the time utility since the last last purchase within item category cj until time k. if user i has not purchased within item category cj until time k, the larger the value of d t, the less likely she needs this item. in this paper , we propose a demand-aware recommendation algorithm for one -sided data. the proposed algorithm is based on a sparse matrix and a sparse matrix with low rank. the sparse matrix is constructed from the frontal slice of a low rank matrix. in this paper we examine it as a tensor nuclear norm minimization problem that seeks jointly learn form utility tensor and a vector of inter-purchase durations, and propose a scalable optimization algorithm with a tractable time complexity. our empirical studies show that the proposed approach can yield perfect recovery of duration vectors in noiseless settings; it is robust to noise and scalable as analyzed theoretically.", "1015": "we present a neural response generation model that generates responses conditioned on a target personality. the model learns high level features based on the target personality, and uses them to update its hidden state. our model achieves performance improvements in both perplexity and bleu scores over a baseline sequence-to-sequence model, and is validated by human judges. in this paper we propose a personality based model which is designed to generate responses conditioned on a target set of personality traits. the model is designed to generate responses with maximum likelihood which reflect the consensus of the agents that appear in the training data. this kind of response does not characterize a specific personality and thus can result in inconsistent or unwanted personality cues. the model is designed to generate responses conditioned on a target set of personality traits values which the responses should express. the target set of personality traits is represented as a vector p, where pi represents the desired value for the ith trait. this value encodes how strongly should this trait be expressed in the response. thus, the size of p depends on the selected personality model ( e.g., five traits for the big five model) . the model is trained end-to-end by maximizing p ( y x) nj1 p ( yj x, y1 : j1 ) . this model can not generate content for agents which do not appear in the training data, and thus, it is limited. this paper presents a model for generating linguistic responses that are adapted to the personality traits of the customer. the model is tested on a crowd-sourcing service and compared to the baseline seq2seq model in terms of perplexity and bleu score. in both cases, the model achieves a relative decrease in perplexity , and a relative improvement in bleu score. the experiments demonstrate that our model can better model the linguistic variation in agent responses by conditioning on target personality traits. in future work, we would like to generate responses adapted to the personality traits of the customer as well, and to apply our model to other tasks such as education systems. in this paper, we present a model for generating linguistic responses that are adapted to the personality traits of the customer. we experimented with a dataset of 87.5k real customer-agent utterance pairs from social media. we find that leveraging personality encoding improves relative performance up to in bleu score, compared to a baseline seq2seq model.", "1016": "we introduce a stereo correspondence system implemented fully on event-based digital hardware, using a fully graph-based non von-neumann computation model, where no frames , arrays, or any other such data-structures are used. this is the first time that an end-to-end stereo pipeline from image acquisition and rectification , multiscale spatiotemporal stereo correspondence, winner-take-all, to disparity regularization is implemented fully on event-based hardware. using a cluster of truenorth neurosynaptic processors, we demonstrate their ability to process bilateral event-based inputs streamed live by dynamic vision sensors ( dvs) , at up to 2,000 disparity maps per second, producing high fidelity disparities which are in turn used to reconstruct , at low power, the depth of events produced from rapidly changing scenes. the speed and low power requirements of these applications can be effectively met using event-based sensors. event-based stereo provides additional advantages over other depth estimation methods that increase accuracy and save energy, such as high temporal resolution, high dynamic range, and robustness to interference with other agents. this paper proposes a new event - based disparity method that uses a pair of synchronized davis sensors and nine truenorth ns1e boards. the proposed event - based disparity method is implemented using a stereo pair of davis sensors and nine truenorth ns1e boards however, the method is applicable to other spiking neuromorphic architectures, and it is also tested offline on larger models using a truenorth simulator. input rectification , spatiotemporal scaling , feature matching, search for best matches, morphological erosion and dilation, and bidirectional consistency check are all performed on truenorth, for a fully neuromorphic disparity solution. with respect to the most relevant state-of-the-art 17, our method uses less power per pixel per disparity map. we also release the event-based stereo dataset used, which includes kinect-based registered ground-truth. truenorth is a neuromorphic event - based event - based neural network architecture that is designed to address the needs of neuromorphic event - based neural networks for tasks such as pattern recognition and pattern recognition. truenorth is a hierarchical , compositional , object - oriented language the proposed local event - based stereo correspondence algorithm is implemented end-to-end as a neuromorphic event - based algorithm. this consists of systems of equations defining the behavior of truenorth neurons, encased in modules called corelets 1, and the subsequent composition of the inputs and outputs of these modules. depicts the sequence of operations performed by the corelets using inputs from stereo event sensors. the stereo rectification is defined by a pair of functions l , r which map each pixel in the left and right sensor rectified space to a w. on a w splitter neurons per sensor polarity channel, arranged in an optional h. the events at each rectified pixel p h l, r, , , are generated through splitter neurons which replicate corresponding sensor pixels. the ring buffer is implemented by storing events in membrane potentials of memory cell neurons in a circular buffer, and through the use of control neurons which spike periodically to polarize appropriate memory cell neurons. buffers can encode the input at various temporal scales. in this paper we present a novel approach to denoise binary input images from a neural network . the neural network is modeled as a ring - buffer with memory cells , where probe pulses periodically and uniformly query the memory cells for the stored memory contents at each tick, where m neurons are probed at odd ticks and m neurons are probed at even ticks. reset pulses control when to reset one of the t memory cells to zero in preparation of a new input. the probe pulses result in the creation of an output event if during the last tick. after probe event, a reset event decrements the previous membrane potential increase, followed by the restoring of the memory event output during the last probe ( a2 ( v mem p, m, r (t) ) 0, 1k and fr ( v mem p, m, r (t) 0, 1k ) the hadamard product is calculated in parallel across multiple neurons, as k pairwise logical and operations of corresponding feature vector entries, resulting in v dot p, q, k, k. for a set of qt-coded inputs, the wta system is realized by a cascade of ( b1 ) feed-forward pruning networks where each of the pruning networks process only 3-bits of the qt codes and prune the inputs not equal to the bitwise maximum of corresonding 3-bits thermometer codes from all inputs. now starting from the most significant bits, all the inputs smaller than the maximum will be pruned at different stages and only the winner ( s) will survive at the output of the last cascade network. this paper describes the use of a sparse event based stereo camera for estimating 3d structures from images captured using a fast rotating fan and a rotating toy butterfly. we present a fully event based neuromorphic stereo system capable of running on live input event streams, using a fully graph-based computation model, where no frames, arrays or other such data-structures are used. the implemented neuromorphic stereo disparity system achieves these advantages, while consuming less power per pixel per disparity map compared to the stateof-the-art the homogeneous computational substrate provides the first example of a fully end-to-end low-power, high throughput fully event-based neuromorphic stereo system capable of running on live input event streams, using a fully graph-based computation model, where no frames, arrays or other such data-structures are used. experiments on real-world sequences demonstrate the ability of the system to take full advantage of the asynchronous and sparse nature of dvs sensors for low power depth reconstruction, in environments where conventional frame-based cameras connected to synchronous processors would be inefficient for rapidly moving objects. the winner-take-all ( wta) system is a feed - forward neural network that takes as input d code representations of the hadamard products for d distinct candidate disparity levels, and finds the disparity with the largest value, at every tick. for designing a scalable and compact wta system on a neuromorphic hardware, we introduced a novel encoding technique for inputs. in a binary eventbased system, numbers can be efficiently coded using base4 representation where each digit is encoded using a 3-bits thermometer code. note that a thermometer code of length 2n bits can be represented by a qtc of length n/2 bits. while it takes a few more bits than a binary representation, it allows designing a feed-forward subnetworks, compared to eight for a binary representation. latency is further improved with larger bases, but the growth in thermometer code length results in consuming more hardware resources.", "1017": "the task of learning the causal structure underlying a certain phenomenon is undertaken by connecting the set of conditional independences ( cis) readable from the observational data, on the one side, with the set of corresponding constraints implied over the graphical structure, on the other, which are tied through a graphical criterion known as d-separation ( pearl, 1988) . given a collection of distributions , two causal graphs are called interventionally equivalent if they are associated with the same family of interventional distributions, where the elements of the family are indistinguishable using the invariances obtained from a direct application of the calculus rules. do-constraints have appeared first at the very definition of causal bayesian networks ( cbns) in and then were leveraged to design efficient experiments to learn the causal graph in the context of structure learning. a soft intervention affects the mechanism that generates the variable, while keeping the causal connections intact. soft-interventions are widely employed in biology and medicine, where it is hard to change the underlying system, but possibly 2recall that a ci represents a constraint readable from one specific distribution saying that the value of z is irrelevant for computing the likelihood of y once we know the value of x, i.e., p ( y x, z) p ( y x) , x, y, z. the second observation leveraged here follows from another realization by pearl that interventions can be represented explicitly in the graphical model he then introduced what we call f-nodes, which graphically encode the changes due to an intervention and the corresponding parametrization ( see also 16. this is important in our context since the do-calculus tests will be visible more explicitly in the graph. the graph obtained by adding f-nodes to the causal graph is called the augmented graph. we propose a characterization of i-markov equivalence between two causal graphs with latent variables for a given intervention set i that is based on a generalization of docalculus rules to arbitrary subsets of interventions. we show a graphical characterization of i-markov equivalence of causal graphs with latents. we introduce a learning algorithm for inferring the graphical structure using a combination of observational and interventional data and utilizing the corresponding new constraints. this procedure comes with a new set of orientation rules. we formally show its soundness. one of the most celebrated results in causal inference comes under the rubric of do-calculus ( or causal calculus) 18, the calculus consists of a set of inference rules that allows one to create a map between distributions generated by a causal graph when certain graphical conditions hold in the graph. recent work presented a generalization of this result for soft interventions 4. the calculus was developed in the context of hard interventions, and recent work presented a generalization of this result for soft interventions 4. the first rule of the calculus is a d-separation type of statement relative to a specific interventional distribution px, which says that y z w ind implies the corresponding conditional independence ( yw, z) px ( yw) . note that the converse of this rule is the work horse underlying most of the structure learning algorithms found in practice, which says that if some independence hold in p, this would imply a corresponding graphical separation ( under faithfulness) . in the case just mentioned, this would imply that y and z should be separated ind, meaning, they have neither a directed nor a bidirected arrow connecting them. from this understanding i.e., the converse of the other two rules should offer insights about the underlying graphical conditions. the paper introduces the notion of interventional markov equivalence between two causal graphs. this notion is formalized in the following definition. consider the tuples of absolutely continuous probability distributions ( pi) ii over a set of variables. a tuple ( pi) ii satisfies the i-markov property with respect to a graphd ( vl, e) if the following holds for disjoint y, z, w v: ( 1 for i i: pi ( yw, z) pi ( yw) if y z w ind. ( 2 for i , j i: pi ( yw) pj ( yw) if y z w ind. in order to characterize causal graphs that are i-markov equivalent, we draw some insight from the markov equivalence of causal graphs with latents. ancestral graphs, and more specifically mags, were proposed as a representation to encode the d-separation statements of a causal graph among the measured variables while not explicitly encoding the latent nodes. since all the constraints in the i-markov definition can be tested by d-separation statements in the augmented graph, then an augmented mag preserves all those constraints. fci is an algorithm for learning augmented pags. given an independence model over the measured variables, fci learns the skeleton of the augmented pag. function createaugmentednodes () in alg. creates the f-nodes by computing the set s of unique symmetric difference sets from all pairs of interventions in i sigma () maps every f-node to a source pair of interventions, which is used later on to perform the do-tests. the algorithm starts by creating a complete graph of circle edges between v f then, it removes the edge between any two nodes x and y if a separating set between the pair exists and records the set. we also observe that if two nodes x, y are separated given z in augi ( d) , they are also separated given z f since f are root nodes by construction, i.e., all the edges incident on f-nodes are out of them. algorithm follows a similar flow to that of the fci. the problem of learning the causal structure underlying a phenomenon of interest from a combination of observational and experimental data is investigated. the algorithm is sound, i.e., every adjacency and orientation is common for all mag ( augi) whered is i-markov equivalent tod. we pursue this endeavor by noting that a generalization of pearl s do-calculus leads to new tests that can be evaluated against data. these tests, in turn, translate into constraints over the structure itself. we define an interventional equivalence class based on such criteria, and then derive a graphical characterization for the equivalence of two causal graphs ( thm. finally, we develop an algorithm to learn an interventional equivalence class from data, which includes new orientation rules. we introduce a graphical representation that can be used to determine if two causal graphs are interventionally equivalent. we provide a formal graphical characterization of this equivalence. finally, we extend the fci algorithm, which was originally designed to operate based on cis, to combine observational and interventional datasets, including new orientation rules particular to this setting. a pag, which represents a markov equivalence class of a mag, is learnable from the independence model over the observed variables, and the fci algorithm is a standard sound and complete method to learn such an object related work: learning causal graphs from a combination of observational and interventional data has been studied in the literature 3, 11, 7, 20, 8, 12, for causally sufficient systems, the notion and characterization of interventional markov equivalence has been introduced in 9, more recently, showed that the same characterization can be used for both hard and soft interventions. for causally insufficient systems, uses sat solvers to learn a summary graph over the observed variables given data from different experimental conditions. introduces an algorithm to pool experimental datasets together and runs a modification of fci to learn an augmented graph; however, they do not consider characterizing an equivalence class. given an independence model over the measured variables , fci follows a similar flow to that of fci. in phase i, the algorithm initializes a complete graph with circle edges, then it removes the edge between any pair of nodes if a separating set between the pair exists and records the set. in phase ii, the algorithm identifies unshielded triples a, b, c and orients the edges into b if b is not in the separating set of a and c. finally, in phase iii, fci applies the orientation rules. only one of the rules uses separating sets while the rest use mag properties, and soundness and completeness of the previous phases the skeleton is correct and all the unshielded colliders are discovered.", "1018": "neural program induction ( npi) is a pragmatic approach toward modularizing the reasoning process by translating complex natural language query into a multistep executable program. while npi has been commonly trained with the gold sketch or its payoff there, for realistic kbqa applications such gold programs are expensive to obtain and obtain the corresponding answers can be provided for training. the resulting combinatorial explosion in program space, along with extremely sparse rewards, makes npi for kbqa ambitious supervision and challenging. we present complex imperative program induction from terminal rewards ( cipitr) , an advanced neural programmer that propagates reward sparsity with auxiliary rewards, and restricts reward to correct programs using high-level constraints, kb schema, and inferred answer type. cipitr solves complex kbqa considerably more accurately than key-value memory networks and neural symbolic machines ( nsm) . for moderately complex queries requiring 2to 5-step programs, cipitr scores at least higher f1 than the competing systems. on one of the hardest class of programs ( comparative reasoning) with steps, cipitr outperforms nsm by a factor of and memory networks by times.1 the absence of gold programs extremely challenging. main contributions we present complex program induction from terminal rewards ( cipitr) , an advanced neural program induction ( npi) system that is able to answer complex logical, quantitative , and comparative queries by inducing programs of up to 7 using atomic operators and variable types. this, to our knowledge, is the first npi system to be trained with only the gold answer as ( very distant) supervision for inducing such complex programs. cipitr reduces the combinatorial program space to only semantically correct programs by ( i) incorporating symbolic constraints guided by kb schema and inferred answer type, and ( ii) adopting pragmatic programming techniques by the final goal into a hierarchy of subgoals, thereby mitigating the sparse reward problem by considering additional auxiliary rewards in a generic, task-independent way. the massive size of the kb involved ( 13 million entities and million tuples) poses a scalability challenge for prior npi techniques. availability of kb metadata helps standardize comparisons across techniques. the human-notated semantic parse of the questions provide the exact structure of the subgraph and the inference process on it to reach the final answer. as in this work, we are focusing on inducing programs where the gold entity relation annotations are known; for this data set as well, we use the human-annotations to collect all the entities and relations in the oracle subgraph associated with the query. the npi model has to understand the role of these gold program inputs in question-answering and learn to induce a program to reflect the same inferencing. cipitr is a program induction engine that samples from the feasible subset using generic constraints. the key and value embedding is obtained from a gru encoder as q. npi core: the query representation q is fed at the initial timestep to an environment encoding rnn, which gives out the environment state et at every timestep. this, along with the value embedding uvalt1 of the last output variable generated by the npi engine, is fed at every timestep into another rnn that finally outputs the program state ht. ht is then fed into the successive modules of the program induction engine as described below. the outvargen algorithm describes how to obtain uvalt1. procedure : npi core ( et1, ht1, uvalt1) et gru ( et1, u val t1, ht1) output: et, ht operator sampler: it takes the program state ht, a boolean vector p feas t denoting operator feasibility, and the number of operators to sample np. it passes ht through the lookup operation followed by feasibility sampling to obtain the top-np operations ( pt) . this paper introduces cipitr, an end - to - end training method to train a reinforcement learning model on complex real - word problems. cipitr takes a natural language query and generates an output program in a number of steps. a program is composed of actions, which are operators applied over variables, cipitr uses a beam search to obtain multiple candidate programs to provide feedback to the model from a single training instance. finally, in order to learn from the discrete action samples, the reinforce objective we next next describe several learning challenges that arise in the context of this overall architecture. handling complex queries by expanding the operator set and generating longer programs blows up the program space to a huge size of ( numop ( maxvar) m. additionally, whereas the relatively simple nsm architecture could explore a large beam size ( 50100), the complex architecture of cipitr entailed by the cpi problem entailed by the cpi problem could only afford to operate with a smaller beam size ( 20) which further exacerbates the sparsity of the reward space. for example, for integer answers, only a single point in the integer space returns a positive reward, without any notion of partial reward, without any notion of partial reward. this paper proposes a model for program induction that is able to predict the answer type of a human-annotated parse question. the model is able to predict the answer type of a human-annotated parse question with high accuracy. a comparative performance analysis of the proposed cipitr model, the rule-based model and the sparql decomposition approach is in table that take-away from these results is cipitr is indeed able to learn the rules behind the multistep inference process simply from the distance supervision provided by the questionanswer pairs and even perform slightly better in some of the query classes. we present cipitr, an advanced npi framework that significantly pushes the frontier of complex program induction in absence of gold programs. we show that it can generate at least meaningful programs having the desired answer-type or without repeating lines of code. on the other hand the nsmgenerated programs are often semantically wrong, for instance, both in the quantitative and quantitative count based questions, the type of the answer is itself wrong, rendering the program meaningless. this arises once again, owing to the token-by-token decoding of the program by nsm. while npi has been commonly trained with the gold sketch or its program to obtain the program space to only natural language queries and the corresponding answers can be provided for training. we present complex imperative program induction from terminal rewards ( cipitr) , an advanced neural programmer that mitigates sparsity with auxiliary rewards, and uses high-level constraints, kb schema, and inferred answer type. cipitr is an end - to - end program induction engine that is able to generate a large number of candidate programs from a single training instance. the program induction engine is able to generate a large number of candidate programs from a single training instance. in order to learn from the discrete action samples, cipitr uses a beam search to obtain multiple candidate programs to provide feedback to the model from a single training instance. the model is allowed to operate on all the generated variables in order to reach the answer. additionally, whereas the relatively simple nsm architecture could explore a large beam size ( 50100), the complex architecture of cipitr entailed by the cpi problem could only afford to operate with a smaller beam size ( 20), which further exacerbates the sparsity of the reward space. a problem as complex as ours requires not only generic constraints for producing semantically correct programs, but also incorporation of prior knowledge, if the model permits. cipitr is able to learn the rules behind the multistep inference process simply from the distance supervision and even perform the performance of cipitr slightly better in some of the query classes. the query types next in order of complexity are quantitative and quantitative count, which translate to an average of the hardest programs. for nsm and cipitr, seven models with different hyperparameters tuned on each of the seven question types. for the train and valid split, a rule-based query type classifier with accuracy was used to bucket queries into the classes listed in table for each of these three systems. for the train and valid split, a rule-based query type classifier with accuracy was used to bucket queries into the classes listed in table for each of these three systems, we also train and evaluate one single model over all question types.", "1019": "the vast amounts of textual data end users need to consume motivates the need for automatic summarization an automatic summarizer gets as an input one or more documents and possibly also a limit on summary length ( e.g., maximum number of words). the summarizer then needs to produce a textual summary that captures the most salient ( general and informative) content parts within input documents. the summarizer may also be required to satisfy a specific user information need, expressed by one or more queries. therefore, the summarizer will need to produce a focused summary which includes the most relevant information to that need. overall, dual-ces provides a significantly better summarization quality compared to other alternative unsupervised summarizers; and in many cases, it even outperforms that of state-of-the art supervised summarizers. the cross entropy ( ce) method is a monte-carlo optimization framework for solving hard combinatorial problems previously, it was utilized for solving the sentence subset selection problem to this end, the ce-method gets as an input q ( q, d), a constraint on maximum summary length l and an optional pseudo-reference summary sl, whose usage is explained later on. the result of such an invocation is a single length-feasible summary s which contains a subset of sentences selected from d which maximizes q ( q, d). the distilled saliency-based pseudo-feedback to improve the summarization policy search between such switched ( dual) goals serves as a novel aspect of our work. to the best of our knowledge, this on its own, serves as a novel aspect of our work. this paper introduces a novel twostep dual-cascade optimization approach, which utilizes two ces-like invocations. both invocations consider the same sentences powerset solution space. yet, each such invocation utilizes a bit different set of summary predictors, depending on whether the summarizer is quality s goal lay towards higher summary saliency or focus. in the first step, dual-ces relaxes the summary length constraint, aiming at producing a longer and more salient summary. this summary then treated as a pseudoeffective reference summary from which saliency-based pseudo-feedback is distilled. such pseudo-feedback is then utilized in the second step of the cascade for setting an additional auxiliary saliency-driven goal. the ce-method is an extension to dualces that adaptively adjusts the value of hyperparameter l. to this end, we introduce a new learning parameter lt which defines the maximum length limit for summary production ( sampling) that is allowed at iteration t of the ce-method. given a topic statement, which is expressed by one or more questions, and a set of english documents, the main task is to produce a 250-word ( i.e., lmax 250) topic-focused summary. in this paper, we compare the summary quality of dualces to the results that were previously reported for several competitive summarization baselines. these baselines include both supervised and unsupervised methods and apply various strategies for handling the 4r-1.5.5.pl -a -c -m -n -2 -u -p -l saliency versus focus tradeoff. to distinguish between both types of works, we mark supervised method names with a superscript the first line of baselines utilize various surface and graph level features, namely bi-plsa 22, ctsum 24, hiersum 8, hysum 3, multimr 23, qode 16, ra-mds 11, spopt 26, and vaes-a the third line of baselines incorporate various attention models, namely: docrebuild 16, ra-mds 11, spopt 26, and vaes-a the first line of baselines utilize various surface and graph level features, namely bi-plsa 22, ctsum 24, hiersum 8, hysum 3, multimr 23, qode 16, ra-mds 11, spopt 26, and vaes-a in this paper, we propose an unsupervised , query-focused , extractive multi document summarizer called dualces. dualces is an unsupervised , query-focused , extractive multi document summarizer that is based on the dualcascade optimization approach. the pseudo-feedback distillation approach employed between the two steps of dualces has some resemblance to attention models that are used by state-of-the-art deep learning summarization methods 1, 12, first we note that , dual-ces significantly improves over these attentive baselines on rouge-1. on rouge-2 , dual-ces is significantly better than c-attention and similar to crsumsf, while it provides ( more or less) similar quality to crsumsf. closer analysis of the various attention strategies that are employed within these baselines, reveals that, while attsum only attends on a sentence representation level, c-attention and crsumsf further attend on a word level. such a more fine-granular attendance results in an improved saliency for the two latter. yet, while c-attention first attends on sentences then on words, crsumsf performs its attentions reversely. this paper proposes dual-ces a novel unsupervised, query-focused , multi-document extractive summarizer. to this end, dual-ces employs a twostep dual-cascade optimization approach with saliency-based pseudo-feedback distillation. to this end, dual-ces tries to handle the tradeoff by gradually shifting from generating a long summary that is more salient in the first step to generating a short summary that is more focused in the second step. moreover, dualces utilizes the long summary that was generated in the first step for saliency-based pseudo-feedback distillation, which allows to generate a final focused summary with better saliency. in this paper, we propose a novel approach to focus summary production using the ce-method. the ce-method consists of two steps. the first step consists of the ce-method with cem ( qfoc ( q, d) def lmax ( q, d) t. the second step is simply implemented by invoking the ce-method with cem ( qfoc ( q, d) def wq p ( wq p ( wq p ( wq p ( wq p) ) ) . here, the target measure qfoc ( q, d) guides the optimization towards the production of a focused summary, while still keeping high saliency as much as possible. to achieve that, we use an additional focusdriven predictor which bias summary production towards the value of hyperparameter l. moreover, using the pseudo-reference summary sl ( sl) we introduce an additional auxiliary saliency-based predictor, whose goal is to enhance the saliency of produced focused summary. this predictor utilizes pseudo-feedback that is distilled from unique unigram words in sl.", "1020": "this paper presents a tts system that can synthesize speech with close to natural quality while running times faster than real-time on a standard cpu. the modular setup of the system allows for simple adaptation to new voices with a small amount of data. we first demonstrate the ability of the system to produce high quality speech when trained on large, high quality datasets. following that, we demonstrate its adaptability by mimicking unseen voices using to minutes long datasets with lower recording quality. large scale mean opinion score quality and similarity tests are presented, showing that the system can adapt to unseen voices with quality gap of and similarity gap of compared to natural speech for male voices and quality gap of and similarity of for female voices. lpcnet is a wavernn variant that uses a nn model to generate speech samples from the utterance-intime input of cepstrum, pitch and pitch correlation parameters. the lpcnet decoder is a wavernn variant that uses a nn model to predict the lpc residual ( the vocal source signal) and then apply the lpcnet residual. in this paper we propose a new method to train a tts system on multispeaker datasets . the method is based on the idea that the tts system can be considered as a multispeaker same gender network (lpcnet) . the lpcnet is used to train a tts system in a speaker independent setting. in this article we present a new tts system that produces high quality speech while operating at faster than real-time rate without an expensive gpu support. the system is built around three nn models for generating the prosody, acoustic features and the final speech signal. we tested this system using two proprietary tts voice datasets and demonstrated that our system produces high quality speech that is comparable to larger and much slower tacotron2 wavenet systems. the task of creating a high-quality tts system out of a smaller set of audio data is even more challenging. we demonstrated that when we reduce the size of the training data, there is some graceful degradation to the quality, but we are still able to maintain good similarity to the original speaker. the system is composed of three separate neural network blocks prosody prediction, acoustic feature prediction and linear prediction coding net as a neural vocoder. the lpcnet uses its nn to predict the lpc residual ( the vocal source signal) and then apply to it an lpc filter calculated from the cepstrum. this has the advantages of better control over the output of the spectral shape since it depends directly on the lpc filter shape. the system is modular and provides easy control, flexibility and adaptability at the component level. the tests were performed using the amazon mechanical turk ( amt) platform with 50- anonymous and untrained subjects participating in several evaluation sessions, constructed so that each sentence is evaluated by distinct subjects. this paper describes the design and implementation of a new tts system that produces high quality speech while operating at faster than real-time rate without an expensive gpu support. for future work, we plan to allow voice modifications by adding control over voice parameters such as pitch, breathiness and vocal tract.", "1021": "feature selection is an important problem in statistics and machine learning for interpretable predictive modeling and scientific discoveries. code is available at url. this paper considers the problem of finding a feature selection gate that is maximal with respect to the product of marginals pxpy and the joint distribution of ( x, y, pw xpy) and ( x, y, pw xpy) . this problem can be written as finding a sparse selector or gate w rdx such thatd ( pw x, y, pw xpy) is maximal, i.e. supw, w0sd ( pw x, y, pw xpy) this problem can be written in the following penalized form: ( p) : sup ff epxyf ( x , y) epxpyf ( x, y) w0 we can relabel f ( x , y) f ( x , y) and write ( p) as: supff epxyf ( x , y) epxpyf ( x, y) w0 we can relabel f ( x , y) f ( x , y) epxpyf ( x, y) w0 we can relabel f ( x , y) f ( x , y) epxpyf ( x, y) w0 we can re in this paper we propose a new method for feature selection based on nonlinear sparsity in multiple kernel learning and group sparsity in multiple kernel learning and group sparsity in multiple kernel learning and group sparsity in multiple kernel learning and group sparsity in multiple kernel learning and group sparsity in multiple kernel learning and group sparsity in multiple kernel learning and group sparsity in multiple kernel learning and group sparsity in multiple kernel learning and group sparsity in multiple kernel learning and group sparsity in multiple kernel learning and group sparsity in multiple kernel learning and group sparsity in multiple kernel learning and group sparsity in multiple kernel learning and group sparsity in multiple kernel learning and group sparsity in multiple kernel learning and group sparsity in multiple kernel learning and group sparsity in multiple kernel learning and group sparsity in multiple kernel learning and group sparsity in group sparsity in multiple kernel learning and group sparsity in multiple kernel learning in this paper we propose to learn a feature map as a deep neural network. the architecture of the network can be problem dependent, but we focus here on a particular architecture: deep relu networks with biases removed. as we show below, using our sparsity inducing gradient penalties with such networks, results in input sparsity at the level of the witness function f of sic. this is desirable since it allows for an interpretable model, similar to the effect of lasso with linear models, our sparsity inducing gradient penalties result in a nonlinear self-explainable witness function f 23, with explicit sparse dependency on the inputs. deep relu networks with no biases, homogeneity and input sparsity via gradient penalties. in this paper two methods that provably control the false discovery rate ( fdr) in feature selection is an important problem for reproducible discoveries. inspired by importance scores in random forest, we define boosted sic as the arithmetic mean or the geometric mean of controlling the false discovery rate ( fdr) in feature selection is an important problem for reproducible discoveries. we are interested in measuring the conditional dependency between a feature xj and the response variable y conditionally on the other features noted xj hence we propose to use generative models for sampling from xj xj. the principle in hrt that we specify here for sic in algorithm is the following: instead of refitting sic under h0, we evaluate the mean of the witness function of sic on a holdout set sampled under h0 ( using conditional generators for r rounds) and obtain that has now twice the dimension , i.e for each real feature j, there is the real importance score jdx and the importance score jdx. the deviation of the mean of the witness function under h0 from the real distribution gives us p-values. we use the benjamini-hochberg procedure on those p-values to achieve a target fdr. sic is an interpretable linear model that is able to capture nonlinear relationships and are successful in practice as they can capture nonlinear relationships similar to sic. random forests have a heuristic for determining feature importance and are successful in practice as they can capture nonlinear relationships similar to sic. we believe sic can potentially leverage the deep learning toolkit for going beyond tabular data where random forests excel, to more structured data such as time series or graph data. finally, sic relates to saliency based posthoc interpretation of deep models such as while those method use the gradient information for a posthoc analysis, sic incorporates this information to guide the learning towards the important features. we first validate our methods and compare them to baseline models in simulation studies on synthetic datasets where the ground truth is available by construction. for this we generate the data according to a model y f ( x) where the model f ( x) and the noise define the specific synthetic dataset. in particular, the value of y only depends on a subset of features xi, i 1, , p through f (), and performance is quantified in terms of tpr and fdr in discovering them among the irrelevant features. in this paper we introduce a new dependency measure called sic, which can be seen as quantifying how much dependency as measured by a coordinate j. it is to the best of our knowledge the first dependency criterion that decomposes in the sum of contributions of each coordinate, and hence it is an interpretable dependency measure. moreover, j are normalized importance scores of each feature j, and their ranking can be used to assess feature importance. the main advantage compared to lasso is that we have a highly nonlinear decision function, that has better capacity of capturing dependencies between x and y nonconvex sic with stochastic block coordinate descent ( bcd) . we are interested in measuring the conditional dependency between a feature xj and the other features noted xj hence we have the following null hypothesis: h0 : xj y xj pxj xjpyxxj in order to simulate the null hypothesis, we propose to use generative models for sampling from xj xj."}