{"1000": "unsupervised learning approaches appear to be a natural solution to this problem, as they require only unannotated text for train. unfortunately, the best completely unsupervised english pos tagger, making its practical usability questionable at best. our method does not assume any knowledge about the target language across eight european languages, our approach results in an average absolute improvement of over a state-of-the-art baseline, and over vanilla hidden markov models induced with the expectation maximization algorithm. this paper proposes a new model for pos taggers in languages for which no labeled resources are available. the model is based on the feature-hmm of berg-kirkpatrick et al., which is a generalization of the traditional hmm model. the model is based on the log-linear model of berg-kirkpatrick et al., which is a generalization of the traditional hmm model.", "1001": "the paper proposes a novel approach for fv representation of sequences using a recurrent neural network ( rnn). the rnn is trained to predict the next element of a sequence given the previous elements. the paper explores two different approaches for training the rnn for the image annotation and image search tasks. one is based on training a regression problem, and the other on training a classification problem. the rnn-fv is capable of encoding the sequence properties, and as underlying features, we rely on video encodings that are based on single frames or on fixed length blocks of frames. word embedding a word was represented either by word2vec, or by the gmmhglmm representation of 18, projected to a 300d sentence to vgg-encoded-image cca space. the vgg pipeline is cropped in ten different ways into by pixel images, the center, and their xaxis mirror image. the mean intensity is then subtracted in each color channel and the resulting images are encoded by the network. the rnn model consists of three layers: a 200d fullyconnected layer units with leaky-relu activation ( 0.1) , a 200-units long short-term memory ( lstm) layer, and a 500d linear fullyconnected layer. when training the rnn for regression, the same 300d input is used, followed by an lstm layer of size the output layer, in this case, is fullyconnected, where the ( 300 dimensional) word embedding of next word is predicted. this paper introduces a novel fv representation for sequences that is derived from rnns. the proposed representation is sensitive to the element ordering in the sequence and provides a richer model than the additive bag model typically used for conventional fvs. the rnn-fv representation surpasses the state-of-the-art results for video action recognition on two challenging datasets. when used for representing sentences, the rnnfv representation achieves state-of-the-art or competitive results on image annotation and image search tasks. since the length of the sentences in these tasks is usually short and, therefore, the ordering is less crucial, we believe that using the rnn-fv representation for tasks that use longer text will provide an even larger gap between the conventional fv and the rnn-fv . a transfer learning result from the image annotation task to the video action recognition task was shown. the con-ceptual distance between these two tasks makes this result both interesting and surprising.", "1002": "in this paper, we propose a novel method that automatically generates summaries for scientific papers , by utilizing videos of talks at scientific conferences. we hypothesize that such talks constitute a coherent and concise description of the papers, and can form the basis for generating summaries. we use an hmm to model the assumed genera- tive process: during the talk, the speaker generates words for describing ver- bally sentences from the paper, one word at each time step. thus, at each time step, the speaker has a single sentence from the paper, and produces a word that constitutes a part of its ver- bal description. then, at the next time step, the speaker either stays with the same sentence, or moves on to describing another sentence, and so on. given the transcript, we aim to retrieve those source sentences and use them as the sum- mary. the number of words to describe each sentence can serve as importance score, in- dicating the amount of time the speaker spent de- scribing the sentence. this enables to control the summary length by considering only the most most im- portant sentences up to some threshold. moreover, our approach can generate sum- maries of various lengths. this paper proposes a novel automatic method to gener- ate training data for scientific papers summariza- tion, based on conference talks given by authors. we propose a novel automatic method to gener- ate training data for scientific papers summariza- tion, based on conference talks given by authors. we show that the a model trained on our dataset achieves competitive results compared to models trained on human generated summaries, and that the dataset quality satisfies human experts. in the future, we plan to study the effect of other video modalities on the alignment algorithm.", "1003": "emotion detection from text has become a popular task due to the key role of emotions in human-machine interaction. current approaches represent text as a sparse bag-of-words vector. in this work, we propose a new approach that utilizes pre-trained, dense word embedding representations. we introduce an ensemble approach combining both sparse and dense representations. for example, cbow representation for glove source showed a improvement in f1-score relative to word2vec. also, the class method we 2url/ 3url/ 4url 5url/ proposed outperformed the other embedded document representation methods.", "1004": "in this paper, we show that, in addition to text based turn features, dialogue features can significantly improve detection of emotions in social media customer service dialogues and help predict emotional techniques used by customer service agents. we used the context of the dialogue to extract informative features that we refer to as dialogue features. using these features for emotion classification in written dialogues is novel, and as our experimental results show, it improves performance compared to a model based only on features extracted from the turn s text. we treated these two objectives as two classification tasks. a feature can be global, namely its value is constant across an entire dialogue or it can be a local, meaning that its value may change at each turn. each turn ti is a tuple consisting of turn number, timestamp, content where turn number represents the sequential position of the turn in the dialogue, and content is the textual message. the goal of this paper is to predict the agent turn emotion and the customer turn emotion. the paper proposes two models for predicting the agent turn emotion and the customer turn emotion. the first model is svm, which is an svm classifier that generates models that are isomorphic to a kth-order hidden markov model. the second model is svm-hmm, which is an svm classifier that generates models that are isomorphic to a kth-order hidden markov model. the second model is svm-hmm dialogue model, which is an svm dialogue model that generates models that are isomorphic to a kth-order hidden markov model. for predicting the agent turn emotion, the svm dialogue model obtained slightly better results than svm-hmm dialogue model, and reached a macro and micro average f1-score improvements over all dialogues of and 43.5, respectively. these results emphasize the differences between the svm dialogue and svm-hmm dialogue models. for customer turn emotion detection, the svm-hmm dialogue model performed better than the svm dialogue model, and reached a macro and micro average f1-score improvements over all dialogues of and 11.7, respectively.", "1005": "few-shot learning ( fsl) is a topic of rapidly growing interest. typically, in fsl a model is trained on a dataset consisting of many small tasks ( meta-tasks) and learns to adapt to novel tasks that it will encounter during test time. this is also referred to as meta-learning. another topic closely related to meta-learning with a lot of interest in the community is neural architecture search ( nas) , automatically finding optimal architecture instead of engineering it manually. in this work, we propose to employ tools inspired by the differentiable neural architecture search ( d-nas ) literature in order to optimize the architecture for fsl without overfitting. additionally, to make the architecture task adaptive, we propose the concept of metadapt controllers. these modules are added to the model and predict optimal network connections for a given novel task. using the proposed approach we observe state-of-theart results on two popular few-shot benchmarks: miniimagenet and fc100. this paper proposes a new approach for few-shot classification that adapts the architecture at test-time to a specific novel task. in this approach, the architecture of the block is built from feature maps v xi that are linked by mixtures of operations. the input feature map to the block is x0 and its output is xv a mixed operation, o ( i, j) o ( i, j) o ( x) oo exp ( ( ( i, j) o) o ( x) oo exp ( ( ( i, j) o) o ( x) oo exp ( ( ( i, j) o) o ( x) oo exp ( ( i, j) o) o ( x) oo exp ( ( i, j) o) o ( x) oo exp ( ( ( i, j) o) o ( x) oo exp ( ( ( i, j) o) o ( x) oo exp ( ( i, j) o) o ( x) oo exp ( ( i, j) o) o ( x) oo exp ( ( i, j) o ( x) oo exp ( ( i, j) o ( x) oo exp ( in this work we have proposed metadapt, a few-shot learning approach that enables meta-learned network architecture that is adaptive to novel few-shot tasks. the proposed approach effectively applies tools from the neural architecture search ( nas) literature, extended with the concept of metadapt controllers, in order to learn adaptive architectures. we demonstrate that the proposed approach successfully improves state-of-the-art results on two popular few-shot benchmarks, miniimagenet and fc100, and carefully ablate the different optimization steps and design choices of the proposed approach. some interesting future work directions include extending the proposed approach to progressively searching the full network architecture ( instead of just the last block), applying the approach to other few-shot tasks such as detection and segmentation, and researching into different variants of task-adaptivity including global connections modifiers and inter block adaptive wiring.", "1006": "the goal of this paper is to detect egregious conversations in customer care systems. an ineffective interaction requires the expenditure of relatively effort from the user with little return on the investment these efforts can appear as behavioral cues in the large customer inputs and include emotions, repetitions, and more. in examining the conversation logs, we noticed that it is not unusual to find a customer asking to be transferred to a human agent. such a request might indicate that the virtual agent is not providing a satisfactory service. moreover, even if there are human agents, they might not be available at all times, and thus, a rejection of such a request is sometimes reasonable, but might still lead to customer frustration. in order to analyze the emotions that customers exhibit in each turn, we utilized the ibm tone analyzer service, the available publicly online7 . in order to analyze the emotions that customers exhibit in each turn, we infer emotions such as frustration, sadness, anger, etc. in order to analyze the emotions that customers exhibit in each turn, we focused on negative emotions ( neg emo) to identify turns with a negative emotional peak ( i.e., single utterances that carried high negative emotional state, as well as to estimate the aggregated negative emotion intensity throughout the conversation. the goal of this paper is to show how it is possible to detect egregious conversations (i.e., conversations that are extraordinarily bad in some way, those conversations which are extraordinarily bad in some way, those conversations which are too short to be meaningful since the customer never replied or provided more details about the issue at hand). as explained, the goal of this paper were difficult in this context, future work includes collecting more data and using neural approaches for analysis, validating cnn. in this context, future work includes collecting more data and using neural approaches for analysis, validating cnn.", "1007": "this paper presents an analysis into the inner workings of convolutional neural networks ( cnns) for processing text. cnns used for computer vision can be interpreted by projecting filters into image space, but for discrete sequence inputs cnns remain a mystery. we aim to understand the method by which the networks process and classify text. we examine common hypotheses to this problem: that filters, accompanied by global max-pooling, serve as ngram detectors. we show that filters may capture several different semantic classes of ngrams by using different activation patterns, and that global max-pooling induces behavior which separates important ngrams from the rest. finally, we show practical use cases derived from our findings in the form of model interpretability ( explaining a trained model by deriving a concrete identity for each filter, bridging the gap between visualization tools in vision tasks and nlp) and prediction interpretability ( explaining predictions) . this paper addresses the question of whether a given filter is homogeneous and specializes in detecting a specific class of ngrams. we challenge this view and show that filters often specialize in multiple distinctly different semantic classes by utilizing activation patterns which are not necessarily maximized. we also show that filters may not only identify good ngrams, but may also actively supress bad ones. we challenge the view and show that filters often specialize in multiple distinctly different semantic classes by utilizing activation patterns which are not necessarily maximized.", "1008": "a summary generated by editnet may include sentences that were either extracted, or of both types. moreover, per considered sentence, editnet may decide not to take either of these decisions and completely reject the sentence. this demonstrates that, editnet has a high capability of utilizing abstraction, while being also able to maintain or reject the original extracted text whenever it is estimated to provide the best benefit for the summarys quality.", "1009": "this paper presents dimsim, a learned ndimensional phonetic encoding for chinese along with a phonetic similarity algorithm, which uses the encoding to generate and rank phonetically similar words. the encodings are learned from annotated data to separately map initial and final phonemes into n-dimensional coordinates. pinyin phonetic similarities are then calculated by aggregating the similarities of initial, final and tone. dimsim demonstrates a 7.5x improvement on mean reciprocal rank over the state-of-the - art. this paper proposes a new method to learn chinese word encodings based on annotators. the model aims to minimize the sum of the absolute differences between the euclidean distances of component pairs and the average distances obtained from the annotated training data across all pairs for initials ( or finals) c. the parameters a and b are set and by default, but we also show that the performance of our model is not sensitive to the parameter settings. we also incorporate a penalty function, p, for pairs deviating from the manually annotated distance so that more phonetically similar pairs are penalized more highly. the final goal is to map each initial ( or final) to an ndimensional point. we observe that when n 2, the locations of initial coordinates align well with table 2, . in particular, the twelve groups are clustered in a pattern that is defined in section for example, bp, gk, jqx are separated into different clusters. however, while table indicated the basic clusters for the initials, our learned model goes further than table by actually quantifying the inter- and intra-cluster similarities. dimsim is a chinese language counterpart of the named entity translation algorithm soundex ( archives and administration, 2007 ) . dimsim generates phonetically similar candidate words based on learned encodings that capture the pronunciation characteristics of pinyin initial, final, and tone components. using a real world dataset, we demonstrate that dimsim effectively improves mrr by 7.5x, recall by 1.5x and precision by 1.4x over existing approaches. the original motivation for this work was to improve the quality of downstream nlp tasks , such as named entity identification, text normalization and spelling correction. these tasks all share a dependency on reliable phonetic similarity as an intermediate step, especially for languages such as chinese where incorrect homophones and synophones abound.", "1010": "relation detection is a core component of many nlp applications including knowledge base question answering ( kbqa). in this paper, we propose a hierarchical recurrent neural network enhanced by residual learning which detects kb relations given an input question. our method uses deep residual bidirectional lstms to compare questions and relation names via different levels of abstraction. additionally, we propose a simple kbqa system that integrates entity linking and our proposed relation detector to make the two components enhance each other. our experimental results show that our approach not only achieves outstanding relation detection performance, but more importantly, it helps our kbqa system achieve state-of-theart accuracy for both single-relation and multi-relation qa benchmarks. this paper proposes a hierarchical bilstm ( hr-bilstm) model for the kbqa end task. the hr-bilstm model is used to score all relations in the kb that are associated to the entities in elk ( q) by taking into account the maximum overlapping sequence of characters between them. if the matching score is larger than a threshold ( tuned on training set), we will add the constraint entity c ( and rc) to the query by attaching it to the corresponding node v on the core-chain. the hr-bilstm model is used to predict the score of each relation r re : srel ( r; e; q) srel ( r; e; q) where is a constant parameter. for each question q, after generating a score srel ( r; e; q) for each relation using hr-bilstm, we use the top l best scoring relations ( rlq) to re-rank the original entity candidates.", "1011": "in this paper, we propose a human-in-the-loop ( huml) dictionary expansion approach that employs identifying a lightweight neural language model coupled with tight huml supervision to assist the user in building and maintaining a domain-specific dictionary from an input text corpus. the approach is based on the explore/exploit paradigm to effectively discover new instances ( explore) from the text corpus as well as predict new unseen terms not currently in the corpus using the accepted dictionary entries ( exploit) this paper proposes an interactive dictionary expansion tool using a lightweight neural language model. our algorithm is iterative and purely statistical, hence does not require any feature extraction beyond tokenization. it incorporates human feedback to improve performance and control semantic drift at every iteration cycle. the experiments showed high importance of tight huml integration on discovery efficiency.", "1012": "this paper presents a novel approach for textual grounding which is based on a deep net based model. the model is based on a set of image concepts, such as semantic segmentations, detections, and word priors. the energy function is based on a set of image concepts, such as semantic segmentations, detections, and word priors. all those concepts come in the form of score maps which we combine linearly before searching for the bounding box containing the highest accumulated over the combined score map. the search for this box can be solved via an efficient branch and bound 31st conference neural information processing systems ( nips 2017 ) textual grounding is an important but challenging task for human-computer interaction, robotics and knowledge mining. for example, we may want to guide bottle on your left phrase such as an autonomous system, or the plate in the top shelf. while those phrases pose significant challenges for present day textual grounding algorithms, as interpretation of those phrases requires an understanding of objects and images. based on those image concepts, which are represented as score maps, we formulate grounding as a search over all possible bounding boxes. the search for this box can be solved via an efficient branch and bound 31st conference neural information processing systems ( nips 2017 ) in this paper, we propose a novel approach for unsupervised learning of the parameters of a feature space. the method is based on the idea of learning a lower bound e ( x, yj, w) on the energy of the feature space. the lower bound e ( x, yj, w) is computed using a linear combination of word priors and accumulated segmentation masks. the upper bound e ( x, yj, w) is computed using a linear combination of word priors and accumulated segmentation masks.", "1013": "the use of perceptual features ( pfs) in the context of learning implicit generative models through moment matching ( mm) is not well studied. more specifically, we propose a new effective mm approach that learns implicit generative models by performing mean and covariance matching of features extracted from pretrained convnets. more specifically, we propose a new effective mm approach that learns implicit generative models by performing mean and covariance matching of features extracted from all convolutional layers of pretrained convnets. some interesting properties of gfmns include: ( a) the loss function is directly correlated to the generated image quality; ( b) mode collapsing is not an issue; and ( c) the same pretrained feature extractor can be used across different datasets. gfmn is a generative moment matching network autoencoder ( gmmnae) that uses a dcganlike architecture in the generator. the generator is trained with a dcganlike architecture in the generator and then uses the frozen pretrained decoder to map back to image space. gfmns are trained with an adam optimizer (adam optimizer) that uses adam optimizer to compute the moving average of the mean features. gfmns are trained with an adam optimizer (adam optimizer) to perform mean and covariance matching in a pf space induced by a nonlinear kernel function ( a dcnn) that is orders of magnitude larger than the ae latent code, and that we argued is universal in the image domain. we achieve successful nonadversarial training of implicit generative models by introducing different key ingredients: ( 1) moment matching on perceptual features from all layers of pretrained neural networks; ( 2) a more robust way to compute the moving average of the mean features by using adam optimizer, which allows us to use small minibatches; and ( 3) the use of perceptual features from multiple neural networks at the same time. the objective of this paper is to show that if a discriminator can distinguish perfectly between real and fake early on, the generator can not learn properly and the min/max game becomes unbalanced, having no good discriminator gradients for the generator to learn from, producing degenerate models. the discriminator, being pretrained on imagenet, can quickly learn to distinguish between real and fake images. indeed, the discriminator, being pretrained on imagenet, can quickly learn to distinguish between real and fake images. this limits the reliability of the gradient information from the discriminator, which in turn renders the training of a proper generator extremely challenging or even impossible. this is a well - known issue with gan training where the training of the generator and discriminator must strike a balance. if a discriminator can distinguish perfectly between real and fake early on, the generator can not learn properly and the min/max game becomes unbalanced, having no good discriminator gradients for the generator to learn from, producing degenerate models.", "1014": "in this paper, we study the problem of demand-aware recommendation. given a user s intention for an item by comparing the time utility since her most recent purchase within the item category cj until time k, the larger the value of d t, the less likely she needs this item. in contrast, the function h max ( 0, d t) may be employed to measure the underlying inter-purchase duration times of the r item categories. it is understood that the inter-purchase durations for nondurable good categories are large, while for durable good categories the inherent properties are small, or even zero. thus, a user might not purchase an item because she does not derive utility from it, or just because she was simply unaware of it or plans to buy it in the future. in this sense, the demand is mediated by the time utility since the last last purchase within item category cj until time k. if user i has not purchased within item category cj until time k, the larger the value of d t, the less likely she needs this item. in this paper , we propose a demand-aware recommendation algorithm for one -sided data. the proposed algorithm is based on a sparse matrix and a sparse matrix with low rank. the sparse matrix is constructed from the frontal slice of a low rank matrix. on two real - world datasets , tmall and amazon review , we show that our algorithm outperforms six state-of-the-art recommendation algorithms on the tasks of category, item, and purchase time predictions. in this paper we examine it as a tensor nuclear norm minimization problem that seeks jointly learn form utility tensor and a vector of inter-purchase durations, and propose a scalable optimization algorithm with a tractable time complexity. our empirical studies show that the proposed approach can yield perfect recovery of duration vectors in noiseless settings; it is robust to noise and scalable as analyzed theoretically. on two real - world datasets , tmall and amazon review we show that our algorithm outperforms six state-of-the-art recommendation algorithms on the tasks of category, item, and purchase time predictions.", "1015": "we present a neural response generation model that generates responses conditioned on a target personality. the model learns high level features based on the target personality, and uses them to update its hidden state. our model achieves performance improvements in both perplexity and bleu scores over a baseline sequence-to-sequence model, and is validated by human judges. we experimented with a dataset of 87.5k real customer-agent utterance pairs from social media. we find that leveraging personality encoding improves relative performance up to in bleu score, compared to a baseline seq2seq model.", "1016": "we introduce a stereo correspondence system implemented fully on event-based digital hardware, using a fully graph-based non von-neumann computation model, where no frames, arrays, or any other such data-structures are used. this is the first time that an end-to-end stereo pipeline from image acquisition and rectification , multiscale spatiotemporal stereo correspondence, winner-take-all, to disparity regularization is implemented fully on event-based hardware. using a cluster of truenorth neurosynaptic processors, we demonstrate their ability to process bilateral event- based inputs streamed live by dynamic vision sensors ( dvs), at up to 2,000 disparity maps per second, producing high fidelity disparities which are in turn used to reconstruct, at low power, the depth of events produced from rapidly changing scenes. experiments on real-world sequences demonstrate the ability of the system to take full advantage of the asynchronous and sparse nature of dvs sensors for low power depth reconstruction, in environments where conventional frame-based cameras connected to synchronous processors would be inefficient for rapidly moving objects. the winner-take-all ( wta) system is a feed - forward neural network that takes as input d code representations of the hadamard products for d distinct candidate disparity levels, and finds the disparity with the largest value, at every tick. for designing a scalable and compact wta system on a neuromorphic hardware, we introduced a novel encoding technique for inputs. in a binary eventbased system, numbers can be efficiently coded using base4 representation where each digit is encoded using a 3-bits thermometer code. note that a thermometer code of length 2n bits can be represented by a qtc of length n/2 bits. note that a thermometer code of length 2n bits can be represented by a qtc of length 2n bits. while it takes a few more bits than a binary representation, it allows designing a feed-forward subnetworks, compared to eight for a binary representation. latency is further improved with larger bases, but the growth in thermometer code length results in consuming more hardware resources. event based disparity is an event based stereo system capable of running on live input event streams, using a fully graph-based computation model, where no frames , arrays or other such data-structures are used. the implemented neuromorphic stereo disparity system achieves these advantages, while consuming less power per pixel per disparity map compared to the stateof-the-art the homogeneous computational substrate provides the first example of a fully end-to-end low-power, high throughput fully event-based neuromorphic stereo system capable of running on live input event streams, using a fully graph-based computation model, where no frames , arrays or other such data-structures are used.", "1017": "given a collection of distributions, two causal graphs are called interventionally equivalent if they are associated with the same family of interventional distributions, where the elements of the family are indistinguishable using the invariances obtained from a direct application of the calculus rules. we introduce a graphical representation that can be used to determine if two causal graphs are interventionally equivalent. we provide a formal graphical characterization of this equivalence. finally, we extend the fci algorithm, which was originally designed to operate based on cis, to combine observational and interventional datasets, including new orientation rules particular to this setting. a pag, which represents a markov equivalence class of a mag, is learnable from the independence model over the observed variables, and the fci algorithm is a standard sound and complete method to learn such an object related work: learning causal graphs from a combination of observational and interventional data has been studied in the literature 3, 11, 7, 20, 8, 12, for causally sufficient systems, the notion and characterization of interventional markov equivalence has been introduced in 9, more recently, showed that the same characterization can be used for both hard and soft interventions. for causally insufficient systems, uses sat solvers to learn a summary graph over the observed variables given data from different experimental conditions. introduces an algorithm to pool experimental datasets together and runs a modification of fci to learn an augmented graph; however, they do not consider characterizing an equivalence class. given an independence model over the measured variables , fci follows a similar flow to that of fci. in phase i, the algorithm initializes a complete graph with circle edges, then it removes the edge between any pair of nodes if a separating set between the pair exists and records the set. in phase ii, the algorithm identifies unshielded triples a, b, c and orients the edges into b if b is not in the separating set of a and c. finally, in phase iii, fci applies the orientation rules. only one of the rules uses separating sets while the rest use mag properties, and soundness and completeness of the previous phases the skeleton is correct and all the unshielded colliders are discovered.", "1018": "neural program induction ( npi) is the pragmatic approach toward modularizing the reasoning process by translating complex natural language query into a multistep executable program. while npi has been commonly trained with the gold sketch or its program to obtain the program space to only natural language queries and the corresponding answers can be provided for training. the resulting combinatorial explosion in program space, along with extremely sparse rewards, makes npi for kbqa ambitious and challenging. we present complex imperative program induction from terminal rewards ( cipitr) , an advanced neural programmer that mitigates sparsity with auxiliary rewards, and uses high-level constraints, kb schema, and inferred answer type. cipitr solves complex kbqa considerably more accurately than key-value memory networks and neural symbolic machines ( nsm) . for moderately complex queries requiring 2to 5-step programs, cipitr scores at least higher f1 than the competing systems. cipitr is an end - to - end program induction engine that is able to generate a large number of candidate programs from a single training instance. the program induction engine is able to generate a large number of candidate programs from a single training instance. in order to learn from the discrete action samples, cipitr uses a beam search to obtain multiple candidate programs to provide feedback to the model from a single training instance. the model is allowed to operate on all the generated variables in order to reach the answer. additionally, whereas the relatively simple nsm architecture could explore a large beam size ( 50100), the complex architecture of cipitr entailed by the cpi problem could only afford to operate with a smaller beam size ( 20), which further exacerbates the sparsity of the reward space. a problem as complex as ours requires not only generic constraints for producing semantically correct programs, but also incorporation of prior knowledge, if the model permits. cipitr is able to learn the rules behind the multistep inference process simply from the distance supervision and even perform the performance of cipitr slightly better in some of the query classes. the query types next in order of complexity are quantitative and quantitative count, which translate to an average of the hardest programs. for nsm and cipitr, seven models with different hyperparameters tuned on each of the seven question types. for the train and valid split, a rule-based query type classifier with accuracy was used to bucket queries into the classes listed in table for each of these three systems. for the train and valid split, a rule-based query type classifier with accuracy was used to bucket queries into the classes listed in table for each of these three systems, we also train and evaluate one single model over all question types.", "1019": "this paper proposes dual-ces a novel unsupervised, query-focused , multi-document extractive summarizer. to this end, dual-ces employs a twostep dual-cascade optimization approach with saliency-based pseudo-feedback distillation. to this end, dual-ces tries to handle the tradeoff by gradually shifting from generating a long summary that is more salient in the first step to generating a short summary that is more focused in the second step. moreover, dualces utilizes the long summary that was generated in the first step for saliency-based pseudo-feedback distillation, which allows to generate a final focused summary with better saliency. in this paper, we propose a novel approach to focus summary production using the ce-method. the ce-method consists of two steps. the first step consists of the ce-method with cem ( qfoc ( q, d) def lmax ( q, d) t. the second step is simply implemented by invoking the ce-method with cem ( qfoc ( q, d) def wq p ( wq p ( wq p ( wq p ( wq p) ) ) . here, the target measure qfoc ( q, d) guides the optimization towards the production of a focused summary, while still keeping high saliency as much as possible. to achieve that, we use an additional focusdriven predictor which bias summary production towards the value of hyperparameter l. moreover, using the pseudo-reference summary sl ( sl) we introduce an additional auxiliary saliency-based predictor, whose goal is to enhance the saliency of produced focused summary. this predictor utilizes pseudo-feedback that is distilled from unique unigram words in sl.", "1020": "this paper presents a tts system that can synthesize speech with close to natural quality while running times faster than real-time on a standard cpu. the modular setup of the system allows for simple adaptation to new voices with a small amount of data. the system is composed of three separate neural network blocks prosody prediction, acoustic feature prediction and linear prediction coding net as a neural vocoder. the lpcnet decoder is a wavernn variant that uses a nn model to generate speech samples from equidistant-intime input of cepstrum, pitch and pitch correlation parameters. the lpcnet uses its nn to predict the lpc residual ( the vocal source signal) and then apply to it an lpc filter calculated from the cepstrum. this has the advantages of better control over the output of the spectral shape since it depends directly on the lpc filter shape. the system is modular and provides easy control, flexibility and adaptability at the component level. hence, the system is modular and provides easy control, flexibility and adaptability at the component level. the tests were performed using the amazon mechanical turk ( amt) platform with 50- anonymous and untrained subjects participating in several evaluation sessions, constructed so that each sentence is evaluated by distinct subjects. this paper describes the design and implementation of a new tts system that produces high quality speech while operating at faster than real-time rate without an expensive gpu support. the system is built around three nn models for generating the prosody, acoustic features and the final speech signal. we tested this system using two proprietary tts voice datasets and demonstrated that our system produces high quality speech that is comparable to larger and much slower tacotron2 wavenet systems. the task of creating a high-quality tts system out of a smaller set of audio data is even more challenging. we demonstrated that when we reduce the size of the training data, there is some graceful degradation to the quality, but we are still able to maintain good similarity to the original speaker. for future work, we plan to allow voice modifications by adding control over voice parameters such as pitch, breathiness and vocal tract.", "1021": "feature selection is an important problem in statistics and machine learning for interpretable predictive modeling and scientific discoveries. code is available at url. in this paper we introduce a new dependency measure called sic, which can be seen as quantifying how much dependency as measured by a coordinate j. it is to the best of our knowledge the first dependency criterion that decomposes in the sum of contributions of each coordinate, and hence it is an interpretable dependency measure. moreover, j are normalized importance scores of each feature j, and their ranking can be used to assess feature importance. the main advantage compared to lasso is that we have a highly nonlinear decision function, that has better capacity of capturing dependencies between x and y nonconvex sic with stochastic block coordinate descent ( bcd) . we are interested in measuring the conditional dependency between a feature xj and the other features noted xj hence we have the following null hypothesis: h0 : xj y xj pxj xjpyxxj in order to simulate the null hypothesis, we propose to use generative models for sampling from xj xj. the architecture of the network can be problem dependent, but we focus here on a particular architecture: deep relu networks with biases removed. using our sparsity inducing gradient penalties with such networks, results in input sparsity at the level of the witness function f of sic."}