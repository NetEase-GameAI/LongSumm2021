{
  "blog_id": "glorotb10",
  "summary": [
    "The weights at each layer $W$ are initialized based on the number of connections they have.",
    "Each $w \\in W$  is drawn from a Gaussian distribution with mean $\\mu = 0$ with the variance as follows.",
    "$$\\text{Var}(W) = \\frac{2}{n_\\text{in}+ n_\\text{out}}$$  Where $n_\\text{in}$ is the number of neurons in the previous layer from the feedforward direction and $n_\\text{out}$ is the number of neurons from the previous layer from the backprop direction.",
    "Reference: [Andy Jones's Blog]( [url]"
  ],
  "author_id": "joecohen",
  "pdf_url": "http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf",
  "author_full_name": "Joseph Cohen",
  "source_website": "https://www.shortscience.org/user?name=joecohen",
  "id": 70140653
}