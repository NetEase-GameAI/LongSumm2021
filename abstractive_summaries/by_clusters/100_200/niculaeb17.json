{
  "blog_id": "niculaeb17",
  "summary": [
    "The idea in this paper is to develop a version of attention that will incorporate similarity in neighboring bins.",
    "This aligned with the work  [ref]  which presented a different approach to deal with consistency between classes of predictions.",
    "In this work the closed form softmax function is replaced by a small optimization problem with this regularizer:  $$ +\\lambda \\sum_{i=1}^{d-1} |y_{i+1}-y_i|$$  Because of this, many of the neighboring probabilities are exactly the same resulting in attention that can be seen as blocks.",
    "[url]"
  ],
  "author_id": "joecohen",
  "pdf_url": "http://papers.nips.cc/paper/6926-a-regularized-framework-for-sparse-and-structured-neural-attention.pdf",
  "author_full_name": "Joseph Cohen",
  "source_website": "https://www.shortscience.org/user?name=joecohen",
  "id": 74374635
}